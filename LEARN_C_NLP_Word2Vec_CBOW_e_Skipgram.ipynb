{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mbaliu-treino/Desenvolve/blob/main/LEARN_C_NLP_Word2Vec_CBOW_e_Skipgram.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font color=orange><b>Word2Vec: interpretação da linguagem humana com Word embedding</b></font>\n",
        "\n",
        "<font color=gray size=2><a href=https://colab.research.google.com/drive/1k1dHy27lP0iWt356_TNg37TyD4pRG43Z>Arquivo Colab</a></font>\n",
        "\n",
        "<ul><font size=2 color=gray><b>FICHA TÉCNICA</b>\n",
        "<li><a href=https://cursos.alura.com.br/course/introducao-word-embedding><font size=2 color=gray>Word2Vec: interpretação da linguagem humana com Word embedding</a>\n",
        "<li>Carga Horária: 10 h\n",
        "<li>Instrutora: Thiago G Santos\n",
        "<li>Data de Início: 08-2022\n",
        "</ul>\n",
        "\n",
        "<hr color=gray><br>\n",
        "\n",
        "* [Efficient Estimation of Word Representations in Vector Space](https://arxiv.org/pdf/1301.3781.pdf)\n",
        "\n",
        "\n",
        "<h3><b>Conteúdo / Aprendizagem:</b></h3>\n",
        "\n",
        "- "
      ],
      "metadata": {
        "id": "JSeHxPLGhvUz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font color=orange>RESUMO</font>\n",
        "\n",
        "<a href=https://docs.google.com/spreadsheets/d/1tTygYlq9r7nkUsw9a25N5_z57-de_59tSBCIVPw6KUw><font size=2 color=gray>ROTEIROS Data Science</font></a>\n",
        "\n",
        "* <font color=orange><b>"
      ],
      "metadata": {
        "id": "XLGw5JrFFY8e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font color=orange>CURSO</font>\n",
        "\n",
        "**Projeto**: criar um classificador do gênero de nóticias de jornal através de seus títulos.\n"
      ],
      "metadata": {
        "id": "AGVggbpvRpHf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "1. Vetorização de palavras: \n",
        "    - One-Hot-Encoding (Vetor esparso)\n",
        "    - Word2Vec: vetor denso de dimensão fixa\n",
        "\n",
        "Generalização dos contextos das palavras. Esta técnica de vetorização permite operar com a informação do contexto das palavras.\n",
        "\n",
        "**CBOW** - Continous back of words\n",
        "\n",
        "`Moro ____ país.`\n",
        "\n",
        "**SKIP GRAM**\n",
        "\n",
        "`____ França ____`"
      ],
      "metadata": {
        "id": "kSpSUCQKXwj2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a href=https://github.com/alura-cursos/word2vec/blob/aula6/Aula_6.ipynb><font size=2; color=gray>Material de referencial do curso</a></font>"
      ],
      "metadata": {
        "id": "bzJUWzHnlbP_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color=orange>Dados</font>\n",
        "\n",
        "A base de dados será a base de conhecimento para o modelo, fornecendo um conhecimento previamente já consolidado que servirá para o treinamento. No NLP, essa base de dados é conhecimento como *corpus textual*.\n",
        "\n"
      ],
      "metadata": {
        "id": "b5ftlE3vG5QY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Para o output do Colab quebrar as linhas longas\n",
        "from IPython.display import HTML, display\n",
        "\n",
        "def set_css():\n",
        "  display(HTML('''\n",
        "  <style>\n",
        "    pre {\n",
        "        white-space: pre-wrap;\n",
        "    }\n",
        "  </style>\n",
        "  '''))\n",
        "\n",
        "get_ipython().events.register('pre_run_cell', set_css)"
      ],
      "metadata": {
        "id": "g4WhDSW1gNEv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "rGzhwuEf94jZ",
        "outputId": "0f2e8cd8-27e2-4fb7-9480-4a0bcb34b6e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "uri_treino = 'https://caelum-online-public.s3.amazonaws.com/1638-word-embedding/treino.csv'\n",
        "uri_teste = 'https://caelum-online-public.s3.amazonaws.com/1638-word-embedding/teste.csv'"
      ],
      "metadata": {
        "id": "1K9a2renk_Fx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "e70214dd-2e43-4a2e-d2df-a59ccefe60a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Leitura dos dados\n",
        "artigo_treino = pd.read_csv(uri_treino)\n",
        "artigo_teste = pd.read_csv(uri_teste)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "ItvG9Nms953q",
        "outputId": "cd49109e-044c-4452-ef33-7272a7a84ed8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Formato da tabela\n",
        "print(artigo_treino.shape)\n",
        "print(artigo_teste.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "InlmCfSi-N-s",
        "outputId": "f4cebbc5-03c5-4d27-913a-7463213d48c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(90000, 6)\n",
            "(20513, 6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Colunas\n",
        "print(*artigo_treino.columns, sep=', ')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "ER4nh2M6-WMc",
        "outputId": "6c909247-9e4f-4114-e7f8-664a3e9252b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "title, text, date, category, subcategory, link\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Exemplos de registros\n",
        "artigo_treino.sample(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "id": "INLoZvD5_Wgv",
        "outputId": "81232236-83b0-416a-b0c8-ce7eb572cb26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   title  \\\n",
              "56823  Saiba quem são as vítimas dos atentados terror...   \n",
              "6749   Surfista a ser batido em 2015, Medina inicia M...   \n",
              "62676            Música em Letras: Será que a casa caiu?   \n",
              "\n",
              "                                                    text        date  \\\n",
              "56823  A Presidência da França anunciou, nesta quarta...  2015-11-15   \n",
              "6749   Há um ano, Gabriel Medina era um jovem muito p...  2015-02-27   \n",
              "62676  Estabelecida na Rua Padre Cerda, 25, no Alto d...  2015-02-02   \n",
              "\n",
              "        category subcategory  \\\n",
              "56823      mundo         NaN   \n",
              "6749     esporte         NaN   \n",
              "62676  ilustrada         NaN   \n",
              "\n",
              "                                                    link  \n",
              "56823  http://www1.folha.uol.com.br/mundo/2015/11/170...  \n",
              "6749   http://www1.folha.uol.com.br/esporte/2015/02/1...  \n",
              "62676  http://www1.folha.uol.com.br/ilustrada/2015/02...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d8c51162-c6ac-4023-af06-e4cc282db8cd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>date</th>\n",
              "      <th>category</th>\n",
              "      <th>subcategory</th>\n",
              "      <th>link</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>56823</th>\n",
              "      <td>Saiba quem são as vítimas dos atentados terror...</td>\n",
              "      <td>A Presidência da França anunciou, nesta quarta...</td>\n",
              "      <td>2015-11-15</td>\n",
              "      <td>mundo</td>\n",
              "      <td>NaN</td>\n",
              "      <td>http://www1.folha.uol.com.br/mundo/2015/11/170...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6749</th>\n",
              "      <td>Surfista a ser batido em 2015, Medina inicia M...</td>\n",
              "      <td>Há um ano, Gabriel Medina era um jovem muito p...</td>\n",
              "      <td>2015-02-27</td>\n",
              "      <td>esporte</td>\n",
              "      <td>NaN</td>\n",
              "      <td>http://www1.folha.uol.com.br/esporte/2015/02/1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62676</th>\n",
              "      <td>Música em Letras: Será que a casa caiu?</td>\n",
              "      <td>Estabelecida na Rua Padre Cerda, 25, no Alto d...</td>\n",
              "      <td>2015-02-02</td>\n",
              "      <td>ilustrada</td>\n",
              "      <td>NaN</td>\n",
              "      <td>http://www1.folha.uol.com.br/ilustrada/2015/02...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d8c51162-c6ac-4023-af06-e4cc282db8cd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d8c51162-c6ac-4023-af06-e4cc282db8cd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d8c51162-c6ac-4023-af06-e4cc282db8cd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Exemplo de título\n",
        "artigo_teste.iloc[643]['title']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "lypC4l42D1DA",
        "outputId": "2c384b63-35cd-4724-a008-618c3fe66784"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Somos todos imprevisíveis'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font color=orange>**Vetorização**</font>\n",
        "\n",
        "Vetorização de textos\n"
      ],
      "metadata": {
        "id": "53SiScTAEFyL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color=orange>One Hot Encoding</font>\n",
        "\n",
        "Uma forma de representar uma palavra de forma matemática é usar a técnica de vetores. Uma das mais conhecidas é a One-Hot-Encoding que transforma palavras em um vetor binário. Ela é muito usada para tranformar variáveis multinomiais em valores numéricos.\n",
        "\n",
        "Cada palavra se tornará uma dimensão no vetor. Logo a quantidade de dimensões será igual ao tamanho do <font color=orange>**vocabulário**</font>.\n",
        "\n",
        "O produto dessa transformação é uma <font color=orange>**matriz esparsa**</font>.\n",
        "\n",
        "Um problema do One-Hot-Encode é que ele torna cada token desconectada, sem contexto ou referências.\n",
        "\n",
        "Como consequencia teremos muitos dados sem dados relevantes, ou seja, um monte de zeros.\n",
        "\n",
        "* Tabela esparsa (monte de zeros)\n",
        "* Tamanho equivalente à quantidade de classes (palavras)\n"
      ],
      "metadata": {
        "id": "iitCr5Pgmhgz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "vetorizador = CountVectorizer()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "mC5OVIJQRbyH",
        "outputId": "8a70b645-400c-4acd-ee53-d3b770d8a0e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Teste de vetorização \n",
        "texto_exemplo = ['tenha um bom dia',\n",
        "                 'tenha um péssimo dia',\n",
        "                 'tenha um ótimo dia']\n",
        "\n",
        "vetorizador.fit(texto_exemplo)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "OLatCiB4EG_1",
        "outputId": "93d51dd0-5040-441c-b731-f876484e0094"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CountVectorizer()"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Vocabulário\n",
        "vetorizador.vocabulary_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "b_tC_QTJQ7ry",
        "outputId": "83985ef0-c8c0-4665-9542-83820dccd4a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'tenha': 3, 'um': 4, 'bom': 0, 'dia': 1, 'péssimo': 2, 'ótimo': 5}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vetor_teste = vetorizador.transform(['bom', 'um'])\n",
        "# Posição na matriz esparsa\n",
        "print('Posição na matriz esparsa:\\n', vetor_teste)\n",
        "\n",
        "# Vetor de matriz esparsa\n",
        "print('\\nMatriz esparsa:\\n', vetor_teste.toarray())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "SrHBf96bRiAz",
        "outputId": "25cda604-970f-4405-bd98-3ca87eb5fccd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Posição na matriz esparsa:\n",
            "   (0, 0)\t1\n",
            "  (1, 4)\t1\n",
            "\n",
            "Matriz esparsa:\n",
            " [[1 0 0 0 0 0]\n",
            " [0 0 0 0 1 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color=orange>Word2Vec</font>\n",
        "\n",
        "Uma alternativa ao sistema de vetorização One-Hot Encoding com a matriz esparsa é o método Word2Vec que permite a criação de uma **tabela densa de tamanho fixo**.\n",
        "\n",
        "Esse novo vetor é do tipo denso, em que todas as suas dimensões possui um valor numérico.\n",
        "\n",
        "* Vetor denso\n",
        "* Tamanho fixo"
      ],
      "metadata": {
        "id": "KdqjnGIiTUmc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Um dos objetivos do Word2Vec é conseguir ensinar o <font color=orange>**CONTEXTO**</font> para as máquinas. Dando um sentido para as palavras e consequentemente conseguir identificar grupos semelhantes a eles. \n",
        "\n",
        "No exemplo do curso, o contexto das palavras a seguir é o que o nome se refere (nome de carro ou nomes de países). Além disso, há a possibilidade de sub-grupos nos grupos, criando mais relações e contextos.\n",
        "\n",
        "Para isso serão necessários uma grande quantidade de dados, para fazer um treinamento semelhante à de redes neurais. Com o treinamento extensivo é possível extrair o uso do contexto das palavras.\n",
        "\n",
        "A saída do processamento com o Word2Vec é um vetor denso, onde todas as posições possui um valor numérico."
      ],
      "metadata": {
        "id": "a-YwQJj_q4H0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Word2Vec](https://lh3.googleusercontent.com/gmRC2djenrwMuKAe-CahjvIplP-gFfAmArlcbJaTwzXJIYMVAUpiiQX8kcEFt0E9prpUd6koomZpC7IXEOWoxtamNgeQGXG7snDIv_si2vPEQhr2eTri3H5en11fy8qPiAQwjWUc0TsMuLw1hjHJZqs)"
      ],
      "metadata": {
        "id": "rXkoOVajpcNJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <font color=orange>CONTEXTO</font>\n",
        "\n",
        "<h3>Mas como é possível ensinar as máquinas a aprender o contexto?</h3>\n",
        "\n",
        "* <font color=orange>DADOS</font>: Quanto maior a quantidade de dados, melhor será a representação vetorial do Word2Vec.\n",
        "* <font color=orange>TREINAMENTO</font>: tendo um conjunto de dados de entrada e uma saída de número fixo, que representarão os pesos, podemos fazer o treinamento com redes neurais.\n",
        "\n",
        "\n",
        "\n",
        "Para interpretar o contexto, somente a palavra anterior e a seguinte serão usadas."
      ],
      "metadata": {
        "id": "p9Kc4SJe_x-M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TREINAMENTO\n",
        "\n",
        "`Prever a palavra através do contexto`\n",
        "\n",
        "Com as palavras adjacentes, ou seja, o contexto da palavra, para tentar adivinhar qual será a nossa saída. Com isso, podemos ajustar pesos das fuções das camadas ocultas da rede neural.\n",
        "\n",
        "0. Remoção de Stopwords\n",
        "1. ENTRADA: As palavras de contexto serão a entrada do modelo.\n",
        "2. CAMADAS OCULTAS: processamento matemático de inúmeras funções.\n",
        "3. SAÍDA: o conjunto de palavras esperados.\n",
        "\n",
        "Essa técnica de a partir das palavras de contexto tentar adivinhar a palavra ser preenchida é conhecida como CBOW (Continuous Bag of Words)\n",
        "\n",
        "* Processo de treinamento mais rápido."
      ],
      "metadata": {
        "id": "b2BBn59QBhzz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TREINAMENTO 2\n",
        "\n",
        "`Prever o CONTEXTO através da palavra`\n",
        "\n",
        "Neste modelo temos uma palavra e gostaríamos de prever o que vem antes e o que vem depois.\n",
        "\n",
        "1. ENTRADA: uma palavra\n",
        "2. CAMADAS OCULTAS\n",
        "3. SAÍDA: n palavra de contexto\n",
        "\n",
        "Esta técnica é conhecida como **Skip Gram**. \n",
        "\n",
        "* melhor contextualização, com volumes de dados menores"
      ],
      "metadata": {
        "id": "C0iaYzBZDRbs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> \"O CBOW é treinado para realizar a previsão de uma determinada palavra tendo o contexto como informação de entrada, já o Skip-Gram precisa prever o contexto recebendo como input uma palavra. Ambos geram um vetor denso de tamanho predeterminado.\""
      ],
      "metadata": {
        "id": "TaJYofyRJRFn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Com a comparação dos contextos de forma matemática, o modelo será capaz de posicionar os dados de próximas ou mais distantes, usando o contexto como elemento separador."
      ],
      "metadata": {
        "id": "ZF8NfLUuCk2x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Utilização do Word2Vec Pre-treinado\n",
        "\n",
        "1. Buscar uma fonte confiável\n",
        "  * NILC - Núcleo Institucional de Linguística Computacional da USP"
      ],
      "metadata": {
        "id": "H-YKv9wzSLeG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "O contéudo do modelo treinado fornecido traz o token e depois 300 dimensões com valores como saída da rede neural.\n",
        "\n",
        "palavra -> [x, y, ..., z]"
      ],
      "metadata": {
        "id": "XST6XIvmdE8y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download de tokens já construído\n",
        "uri_cbow_300 = 'http://143.107.183.175:22980/download.php?file=embeddings/word2vec/cbow_s300.zip'\n",
        "\n",
        "!wget $uri_cbow_300\n",
        "!unzip \"/content/download.php?file=embeddings%2Fword2vec%2Fcbow_s300.zip\""
      ],
      "metadata": {
        "id": "R8LnZFU4TVSR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "17a9e3d9-8505-42ff-9435-eff0a7a156a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-09-08 21:20:08--  http://143.107.183.175:22980/download.php?file=embeddings/word2vec/cbow_s300.zip\n",
            "Connecting to 143.107.183.175:22980... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 929305948 (886M) [application/octet-stream]\n",
            "Saving to: ‘download.php?file=embeddings%2Fword2vec%2Fcbow_s300.zip’\n",
            "\n",
            "download.php?file=e 100%[===================>] 886.25M  11.2MB/s    in 80s     \n",
            "\n",
            "2022-09-08 21:21:29 (11.1 MB/s) - ‘download.php?file=embeddings%2Fword2vec%2Fcbow_s300.zip’ saved [929305948/929305948]\n",
            "\n",
            "Archive:  /content/download.php?file=embeddings%2Fword2vec%2Fcbow_s300.zip\n",
            "  inflating: cbow_s300.txt           \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Leitura do arquivo de tokens\n",
        "cbow_300_path = '/content/cbow_s300.txt'\n",
        "\n",
        "with open(cbow_300_path) as file:\n",
        "  for linha in range(10):\n",
        "    print(next(file))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7Jv03siaTijh",
        "outputId": "9526d86a-956a-44ab-e457-c619622b35f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "929606 300\n",
            "\n",
            "</s> -0.001667 -0.000158 -0.000026 0.001300 -0.000796 0.001527 0.000046 0.000584 0.000449 -0.000100 0.000353 0.001251 0.001069 0.000506 0.000574 0.000838 -0.000930 -0.001220 0.000317 0.001315 -0.001120 0.001373 -0.000040 -0.001580 0.000421 -0.000667 -0.001556 -0.000746 0.001604 0.001157 -0.000027 0.000354 0.000358 -0.000527 -0.000573 -0.001512 -0.001557 -0.001637 0.001617 -0.001511 -0.001022 -0.001426 0.001086 -0.001033 0.000593 0.000724 0.000627 -0.000450 -0.001140 0.000333 0.000524 0.001541 0.000284 0.000617 -0.000807 -0.000088 -0.000364 0.001126 -0.001230 -0.001138 -0.001280 0.001330 0.001257 0.000576 0.000764 0.000684 0.001008 -0.000215 -0.000629 -0.001228 -0.001557 -0.000311 -0.000246 0.000045 0.001136 -0.000645 -0.000549 0.001099 0.000858 -0.000886 0.000553 0.000303 0.001433 0.000732 0.001321 -0.000894 -0.000700 -0.000661 -0.001484 -0.000950 -0.001556 -0.000809 0.000348 -0.000068 0.000724 -0.000569 -0.000161 -0.001628 -0.001437 -0.000259 -0.000296 -0.001571 0.000149 0.000847 0.000613 0.000802 0.001507 0.001015 0.000377 0.000255 -0.000458 -0.000777 -0.001561 0.001601 -0.001520 -0.001210 0.000106 0.000714 0.000392 0.001311 -0.001192 -0.000090 -0.001097 0.000424 -0.000954 -0.001272 -0.001178 0.000036 -0.000181 0.000331 -0.001453 -0.001488 -0.001033 -0.000377 0.000257 -0.001418 0.001109 0.000722 0.000936 -0.000113 0.001215 -0.000263 0.000652 0.001190 -0.000258 0.001391 0.001213 0.000783 -0.001202 0.000470 -0.000879 0.000688 -0.001163 -0.001105 0.001497 0.001304 -0.001322 -0.001501 0.001377 0.001439 0.000884 0.000484 0.001239 -0.001578 0.000981 -0.000318 -0.001180 -0.001375 -0.001491 0.001057 -0.001028 0.000893 0.001028 0.000772 0.001636 -0.000331 -0.000247 -0.001006 -0.000329 0.000837 0.000605 -0.000959 0.001410 0.000488 0.001167 -0.000293 -0.001188 -0.000001 0.001135 0.001141 0.001504 0.000198 -0.001060 0.001551 -0.000003 -0.001474 -0.000391 -0.000880 0.000433 -0.000976 -0.001417 0.000563 -0.001188 0.000593 0.001584 -0.001602 -0.000439 -0.001148 -0.001256 0.001185 -0.000738 0.001543 -0.000846 -0.001029 -0.000641 -0.001587 0.001439 -0.001251 0.000942 -0.001414 -0.001106 0.001087 -0.000027 0.000757 -0.000159 -0.001014 -0.000891 0.000024 -0.000238 0.000157 -0.001067 0.000902 -0.001050 -0.000428 -0.001606 -0.000988 0.001391 0.001165 -0.000113 -0.001000 -0.000055 -0.001369 0.000684 0.000715 0.001407 0.000613 0.001389 0.001315 -0.000130 -0.001044 0.000175 -0.000035 0.000959 -0.000345 0.001209 -0.001251 -0.001219 0.001231 -0.000996 -0.001388 0.001038 0.001336 -0.001066 -0.000881 -0.001066 -0.001466 -0.000274 0.000201 0.000401 0.000132 0.000588 0.000589 -0.000128 0.001073 0.001197 0.000109 0.000770 0.001221 0.000996 -0.001174 0.000135 -0.001134 -0.001385 -0.000311 -0.001631 -0.000564 0.001162 -0.000322 -0.000469 0.001312 -0.001402 0.000239 0.000184 0.001300 0.000021 -0.001065 0.000047 -0.000301 0.001336 0.000332\n",
            "\n",
            ", -0.061483 -0.094368 -0.008557 -0.034702 0.021108 -0.011873 -0.041133 -0.095925 0.034668 -0.085286 0.076174 0.003314 0.019222 -0.038695 -0.008963 0.053399 0.162935 0.050372 -0.020163 -0.027230 0.061531 0.060840 0.074610 -0.056173 0.007621 -0.055220 0.018008 0.026096 0.033154 -0.082612 -0.081761 0.164978 -0.034423 0.003094 -0.018217 -0.087445 -0.074446 -0.000142 0.004218 0.036585 0.016095 -0.129141 -0.119698 -0.053717 0.005053 -0.114520 -0.017219 0.023693 -0.024115 0.053125 0.024658 -0.037689 0.012078 0.112701 0.028037 0.047618 -0.024196 0.050112 -0.073095 -0.090859 -0.030613 -0.109599 0.037756 0.063827 0.022537 -0.029640 -0.016311 0.021875 0.064882 0.039002 -0.082970 -0.043166 0.013695 -0.043153 -0.082203 -0.020087 -0.100360 0.007033 -0.074208 -0.067789 -0.024897 -0.020358 0.041731 0.101332 0.020217 -0.032473 0.087827 -0.033611 -0.150526 -0.016615 0.021147 -0.025058 0.097833 0.065067 0.051287 -0.079191 0.089563 -0.008436 -0.038352 0.019787 -0.058452 -0.009696 -0.051077 -0.112245 0.024886 -0.015172 -0.129670 0.068672 0.068483 0.009049 0.007055 -0.032763 0.001527 0.054264 0.029924 -0.023482 0.047470 0.008044 0.014534 0.071155 0.016700 -0.027491 -0.155782 0.039370 0.116605 -0.001262 -0.026638 -0.067078 0.078015 -0.066153 -0.039303 0.009535 -0.055698 -0.022250 0.046948 0.053810 0.038096 0.032157 -0.075257 0.008125 -0.034598 -0.020667 -0.003153 0.032491 -0.031064 0.030744 -0.049023 -0.046149 0.000792 0.010385 -0.057119 -0.122554 0.003210 -0.054363 -0.100899 0.069873 -0.009758 0.055455 0.049243 0.008346 -0.016087 0.093572 0.024125 0.058736 0.037243 -0.007478 0.032175 -0.054205 0.008798 0.032326 0.028384 -0.032259 -0.041842 -0.058281 -0.025145 0.011097 0.023598 -0.033376 0.026204 0.032505 -0.009283 0.041076 0.055565 -0.081757 -0.010077 0.058251 -0.014379 -0.040951 0.006938 -0.004179 0.052006 -0.063725 0.035674 -0.066554 0.030910 -0.004032 0.077445 0.029495 -0.064931 0.040263 -0.055423 -0.021571 0.086767 -0.003583 0.073308 -0.043991 0.022503 -0.028692 -0.063626 -0.048238 0.013439 -0.043673 -0.101352 -0.004321 0.125507 0.088486 0.042756 -0.014497 -0.053445 0.021800 0.038406 -0.034023 -0.074428 -0.132825 0.082152 -0.068497 0.004738 0.047527 -0.073890 0.051089 -0.055886 -0.047786 0.040247 -0.053966 -0.015752 0.099451 0.008218 -0.010716 -0.031540 0.036168 0.054244 0.051809 0.035158 0.043006 -0.027902 0.000130 0.103397 -0.114831 -0.036648 -0.036143 0.024432 0.084740 0.001801 0.044475 -0.035746 -0.024109 0.051210 -0.025769 0.016073 -0.000351 -0.029183 -0.075292 0.042163 0.025010 -0.041439 -0.059192 0.026617 -0.040852 0.034697 0.014691 -0.057382 0.046141 0.070360 0.045274 0.065880 0.011023 -0.031292 -0.015784 -0.023421 -0.042788 0.019669 0.035010 0.036188 -0.058060 -0.093562 0.030321 -0.054753 0.097162 0.001134 0.018939 -0.150218 -0.009928 0.051118 0.105212 -0.055051 -0.047959 -0.136800 -0.003198 0.068969 -0.022456\n",
            "\n",
            "de -0.232068 0.066729 0.103946 -0.072608 0.126237 -0.004782 -0.025139 -0.141489 -0.069438 -0.071078 0.175772 -0.017257 0.094824 0.011020 0.029226 -0.010670 0.144973 0.105333 -0.088273 -0.070952 0.054747 -0.048955 -0.047809 -0.030763 -0.052293 -0.003596 0.078465 0.144430 0.129697 -0.078427 -0.025080 0.212887 0.119806 0.101703 -0.142488 -0.031272 -0.026594 -0.109429 -0.154688 -0.121492 -0.103781 -0.177948 -0.125544 -0.120136 0.031658 0.054160 0.060493 -0.115676 0.132511 -0.001668 -0.125569 -0.124120 0.029025 0.006200 -0.007915 0.058489 0.122710 0.004660 -0.082200 0.123740 0.052747 -0.065657 0.154747 0.155071 0.003547 -0.154675 -0.035110 0.119117 0.080579 0.044262 0.048753 0.054975 -0.064624 -0.046866 0.028242 0.144197 0.029916 -0.024569 0.195781 -0.028608 -0.008233 -0.032542 0.012042 0.011934 -0.068173 0.037028 0.018363 -0.038244 -0.091176 -0.019795 0.051640 -0.008025 -0.025825 -0.001686 -0.069845 -0.039987 0.066244 0.088229 -0.171358 -0.030783 0.082344 0.059267 0.000550 -0.216285 -0.201356 -0.131063 -0.033069 -0.057126 -0.127576 -0.099251 -0.044669 0.035363 -0.119503 -0.090019 -0.006226 -0.000546 0.020731 0.016140 -0.007438 0.032885 -0.161048 0.105681 -0.115705 -0.078013 0.102293 -0.107958 -0.025926 -0.067986 0.017502 -0.054865 -0.007930 -0.006999 -0.000949 -0.026097 0.106295 0.115368 -0.033742 -0.046025 0.009641 -0.065890 0.198822 0.078333 0.062547 0.044947 -0.098424 0.140951 0.109045 -0.004204 -0.174950 0.034234 0.040793 -0.210289 0.104861 0.083616 -0.042511 -0.031439 -0.113108 0.000401 -0.171665 0.097890 0.008065 0.080684 -0.009576 -0.042125 0.177337 -0.005585 -0.004165 0.069755 -0.100323 -0.023289 0.039458 -0.089292 0.069543 -0.009576 0.011562 -0.076654 0.009681 -0.018808 -0.047881 0.026709 -0.021200 -0.032544 0.100362 0.037157 0.005169 -0.001280 -0.064330 -0.049024 -0.002354 0.004443 0.049129 0.026813 0.034249 0.068827 -0.038583 -0.116914 -0.107378 0.046983 0.038218 -0.082186 -0.124208 0.066872 -0.081745 -0.016516 0.016110 0.046844 0.176223 0.083604 -0.086893 -0.114739 -0.159588 0.007700 0.004887 0.006024 -0.020026 0.045816 0.033604 0.054474 0.089348 -0.024353 0.104835 0.084334 0.052662 -0.041422 -0.027877 0.002816 0.150068 -0.052310 0.017154 -0.152326 0.067753 -0.082644 0.119430 -0.012345 0.082965 -0.005791 -0.082770 -0.030068 -0.037331 -0.075347 0.035060 -0.092023 -0.001051 0.012675 0.128757 -0.048579 -0.078527 -0.134126 -0.060009 0.096834 -0.045947 0.132404 -0.030576 -0.006618 -0.088179 -0.124597 -0.095311 -0.086943 0.007010 0.059925 -0.077005 -0.035458 -0.017957 0.081104 0.060141 0.152996 0.083737 -0.025909 0.005420 -0.006300 -0.075839 -0.012399 -0.001624 0.039090 -0.040755 -0.013051 -0.072733 -0.048062 -0.082573 -0.013851 -0.120222 0.011452 -0.083538 0.015996 -0.110800 0.012405 0.045823 0.026705 -0.040789 0.064309 0.007381 -0.037854 0.076050 0.104702 0.010307 -0.103478 0.085227 0.064233 -0.015908 -0.047998\n",
            "\n",
            ". 0.027867 0.077901 -0.054738 -0.095938 -0.010536 0.015269 -0.005752 -0.048440 -0.104021 0.054583 0.050108 0.054979 0.071112 -0.056665 -0.140868 0.203626 0.211330 0.137270 -0.038069 -0.108607 0.060027 0.052436 0.126758 -0.078212 0.008864 -0.028087 0.029884 0.114899 -0.058657 -0.166441 -0.188866 0.294844 -0.147703 -0.095883 -0.104021 -0.097608 -0.172317 0.035795 -0.019025 0.057503 -0.030564 -0.125182 -0.257359 -0.106566 -0.002708 -0.035769 -0.072053 -0.005640 0.016920 0.155101 -0.226088 -0.070904 -0.110280 -0.075773 -0.190123 0.197397 -0.108603 0.155954 0.096544 -0.183301 0.008154 -0.195997 0.035284 -0.025561 0.159142 -0.141005 0.140643 -0.160588 0.140709 0.059974 -0.012396 -0.074953 -0.038325 -0.165941 -0.226005 -0.043738 0.052905 0.085072 -0.165731 0.016894 -0.136569 0.088165 -0.032044 0.022789 0.051207 0.015907 0.093662 0.037576 -0.286139 -0.107587 0.165001 0.095293 0.181427 0.038072 0.078180 -0.116599 0.138464 0.138386 0.020201 -0.028087 0.038829 -0.040074 -0.044944 -0.179895 0.035044 0.090347 -0.036088 0.154828 0.090421 0.172175 -0.127294 0.060227 0.164694 0.141367 0.049326 -0.136940 0.060633 -0.089581 -0.069639 0.043680 0.141455 -0.060588 -0.118859 0.181506 -0.051302 0.165763 0.151366 -0.191232 -0.103888 -0.077344 -0.016534 0.073607 -0.008464 0.216368 0.038251 0.002552 -0.112613 -0.049596 0.018040 -0.032907 -0.131335 -0.049530 0.057485 0.129446 -0.017884 0.075667 -0.061577 -0.015305 0.007649 0.116636 -0.132568 -0.244250 -0.048748 0.003139 -0.123311 0.018462 0.126955 0.079116 -0.067653 0.019126 0.044182 0.037610 0.199809 -0.118487 0.011276 -0.061652 -0.034426 -0.120148 -0.171490 0.009182 0.182921 -0.165212 0.149898 0.062080 -0.129040 0.051808 -0.075070 -0.068688 0.018707 -0.008050 0.108429 -0.111089 0.021230 -0.125982 0.077740 0.140251 -0.051900 0.036107 0.019580 -0.084050 0.065747 0.015718 -0.016900 -0.026964 0.126565 -0.087491 0.069504 0.108362 -0.006355 0.118521 -0.002510 0.060457 0.082848 0.000294 -0.037938 -0.026097 0.084446 0.015568 -0.050540 -0.117080 0.100227 -0.046050 -0.059615 0.086632 0.097266 0.084578 -0.036891 -0.033246 0.021302 -0.149581 -0.006353 -0.035713 -0.177163 -0.016629 -0.028634 -0.147015 -0.017861 0.009931 -0.181849 0.065564 -0.007616 0.094861 0.089787 0.005743 -0.127185 0.093027 -0.107247 -0.019161 -0.201082 -0.008504 0.126500 0.034318 0.011876 0.012696 -0.090981 0.012814 0.038388 -0.274763 -0.123303 -0.073078 0.027702 0.035841 -0.080954 0.091305 0.029009 -0.006000 0.121087 0.016678 -0.070181 -0.080839 -0.016332 -0.081390 -0.059594 0.131390 0.039603 -0.222503 -0.039382 -0.071041 0.267399 -0.010011 -0.077326 -0.044107 0.052901 0.023623 -0.087243 0.011539 -0.006381 -0.074194 -0.041591 -0.061872 -0.098552 -0.094357 -0.062879 -0.150341 -0.087596 0.330078 0.028435 0.087784 0.034434 -0.008122 -0.258485 -0.109828 0.013279 0.043340 0.136803 -0.081573 -0.136733 -0.081884 0.306241 0.093106\n",
            "\n",
            "a -0.019764 -0.096043 -0.010960 0.102012 -0.101848 -0.010257 0.004692 -0.165735 -0.179723 0.067659 0.037108 0.100931 -0.211779 0.163603 -0.042376 -0.021683 -0.014900 0.101581 -0.053583 0.065435 0.126251 0.062320 -0.057445 -0.107130 -0.037044 -0.072958 -0.066655 -0.067962 -0.070879 -0.187941 0.065208 0.102302 -0.024876 0.151433 0.012228 -0.065570 -0.063793 0.015519 0.046230 0.174824 -0.100376 -0.081244 -0.039337 0.017851 0.125168 -0.096404 -0.133070 -0.023451 0.117965 0.005949 0.038928 0.060488 -0.014678 0.024891 -0.001455 0.048539 0.133535 0.084564 0.018362 -0.054294 -0.235691 -0.151528 0.043101 -0.097685 -0.034775 -0.127507 0.010346 -0.010458 0.047631 0.002045 -0.013826 -0.139644 0.128220 -0.020997 -0.057176 0.007458 -0.033133 -0.083235 -0.075585 -0.079414 -0.023531 0.076794 0.051968 0.026857 0.007574 -0.039602 0.027458 -0.146083 0.008662 0.113647 0.007963 0.023413 0.088046 -0.079530 0.027995 -0.017113 -0.056750 0.069447 0.094213 0.123728 0.010051 -0.054795 0.041003 -0.044294 -0.066911 -0.025221 0.059618 0.023494 -0.095354 0.029266 0.047979 0.079102 -0.061757 0.116363 0.011112 0.136784 -0.027020 -0.002793 -0.092629 -0.047217 0.111263 0.102819 0.090932 -0.085343 -0.026490 -0.033315 -0.028970 -0.118673 -0.067360 -0.207183 -0.076011 0.017469 -0.078908 0.031023 0.090820 -0.054443 0.062466 0.065952 -0.028265 0.051329 0.090671 0.106923 0.028011 0.014720 -0.036025 0.099207 -0.013510 -0.147551 -0.077657 -0.099269 0.001171 0.059405 -0.006946 0.123997 0.023131 0.102308 -0.040784 0.027455 -0.181898 0.095958 0.155467 -0.077250 -0.124941 0.058529 0.035851 -0.004447 0.035127 -0.024015 -0.029101 -0.107558 0.055650 -0.017027 0.008997 -0.016504 0.018768 -0.080671 0.029003 0.013937 0.002876 -0.064262 0.001246 0.073494 -0.013986 -0.100303 0.027376 0.030375 -0.177618 0.016413 -0.008711 -0.257308 -0.031904 0.068326 0.038748 0.006762 -0.045245 0.038158 0.093055 -0.069432 -0.140442 -0.030486 -0.097529 0.251017 -0.059000 -0.037363 -0.020030 0.116937 0.018191 -0.005464 0.016485 0.009930 0.007318 -0.131821 -0.005316 -0.063905 0.066936 -0.007235 0.066709 0.153262 -0.087015 -0.196866 0.042973 0.124447 0.034619 -0.021113 0.029881 -0.072679 0.068707 -0.033823 -0.140311 -0.158137 0.215081 -0.020170 -0.062018 -0.038955 0.158768 -0.155656 0.016471 -0.071324 0.069629 -0.070692 0.114725 0.114054 0.154133 -0.143244 -0.082015 -0.070578 0.094558 -0.073491 -0.084676 0.089027 -0.053428 0.034783 0.007488 0.008849 0.137206 -0.061942 -0.155206 -0.022297 -0.054165 0.206418 0.058566 0.033847 0.039555 0.042072 -0.003160 0.350700 -0.067416 -0.089351 0.147734 0.026404 -0.128322 -0.143885 -0.189820 0.162824 -0.038651 -0.045660 0.083507 0.118510 -0.054740 -0.053446 -0.106545 -0.087144 -0.159905 0.006153 0.057539 0.079486 -0.015659 -0.014220 -0.013549 -0.122177 -0.154875 0.319072 -0.251233 0.070468 -0.084041 -0.067580 -0.163386 -0.026553 -0.033245 -0.035199\n",
            "\n",
            "o 0.050016 0.094213 -0.234393 0.057870 -0.255710 -0.099076 0.162541 -0.073166 -0.072231 0.087253 0.154162 -0.021438 0.095246 0.086680 0.027481 0.055959 0.176635 -0.158901 -0.076106 -0.036695 0.115689 -0.039255 -0.116532 -0.143528 0.059030 0.049429 -0.009721 0.204578 -0.020946 -0.254149 -0.167956 0.024087 -0.094412 -0.066287 -0.085987 -0.081115 -0.035314 -0.000736 0.069831 -0.034319 -0.041741 0.007945 0.106777 0.119971 -0.051358 0.152951 -0.109669 0.102599 0.102598 0.044424 -0.088313 0.142374 0.042868 -0.042467 0.199348 -0.234265 -0.044845 -0.109492 0.005783 -0.045873 -0.049017 -0.037446 0.105329 -0.163747 -0.139140 0.153179 -0.117726 -0.113436 0.010813 0.097110 0.074618 0.041083 0.082912 -0.052041 0.009895 0.160828 0.058190 -0.215907 -0.024543 0.042466 -0.011712 0.064930 0.097498 -0.080108 0.019837 -0.059179 0.077248 -0.135312 0.132748 0.069083 0.075949 -0.232743 0.078279 -0.078944 0.116486 0.004099 0.057786 -0.125938 0.068976 0.176170 0.044454 0.085901 0.033849 0.057793 -0.083662 0.061258 -0.037814 0.050392 -0.067302 -0.102103 -0.011153 0.029286 0.032976 0.003400 0.061664 0.076337 -0.097293 0.026432 -0.059397 -0.160978 0.069399 0.307550 0.069981 -0.122410 0.003086 0.027841 0.134213 -0.018279 -0.025608 -0.156602 0.062460 -0.051757 0.030337 -0.042270 0.007516 0.055478 0.075345 0.112685 -0.047181 0.001009 0.031433 -0.134699 -0.034702 -0.082685 -0.182748 -0.097813 0.053774 -0.067876 -0.090774 -0.035145 0.080364 -0.242563 0.024905 -0.012293 0.110051 0.103592 0.138403 -0.035121 0.037955 -0.028042 0.005687 0.042462 0.045434 0.127590 -0.049950 0.079609 -0.152268 -0.102837 -0.083840 -0.132681 -0.073176 0.031672 0.104991 0.082840 0.142188 -0.047643 0.054661 -0.112325 0.006551 0.079335 0.011705 -0.042121 0.086597 0.088994 0.079949 -0.002677 0.106816 -0.055035 0.068153 -0.167192 0.009149 -0.028594 -0.039560 0.001607 -0.122615 0.106024 0.107250 0.050540 -0.043291 0.061397 0.001380 0.054964 0.040893 -0.045046 0.002312 0.032035 -0.026698 -0.042064 0.144622 0.076241 0.024255 -0.086833 0.098275 -0.083894 0.086363 -0.004560 -0.029056 0.126784 0.071785 -0.025692 0.000966 0.100620 0.030299 -0.163968 0.042070 -0.198341 0.099603 -0.113758 0.124685 -0.069966 -0.165131 -0.134782 -0.020419 -0.112747 0.123515 -0.045274 0.167949 -0.109681 -0.146224 0.075453 0.054352 0.023153 -0.062161 -0.059457 -0.124327 0.041855 0.205124 -0.083616 -0.062827 0.017066 0.025000 0.079311 0.018874 -0.055492 -0.129246 0.099183 -0.022749 -0.079510 -0.130005 0.012160 0.060842 0.018816 -0.180103 0.057191 0.018971 0.216519 -0.003726 0.155861 0.112271 0.091379 -0.073707 -0.059254 0.011068 -0.005690 -0.098677 -0.082454 0.105838 0.042144 0.100894 0.096960 -0.228625 0.064737 0.022971 -0.001549 -0.105277 0.149519 -0.055187 0.201671 0.098550 0.056229 -0.107189 -0.005223 -0.077126 0.020865 -0.098107 0.064205 -0.174567 0.196321 0.233813 0.038634\n",
            "\n",
            "e -0.168088 -0.001531 0.017038 -0.137315 -0.026399 -0.018215 0.026076 0.019779 -0.095212 -0.090352 -0.106060 0.061975 -0.000318 -0.002945 0.119734 0.149804 0.108117 0.064784 0.065574 -0.038343 0.159915 -0.006124 -0.038307 -0.094810 -0.019356 -0.045115 -0.121859 0.028930 0.045017 -0.138268 0.099283 0.128659 0.077656 0.032982 -0.086139 0.051552 -0.077685 -0.066857 -0.045233 -0.185625 0.013728 -0.067088 -0.061796 0.091931 0.007931 -0.033784 -0.026604 0.026487 0.002281 0.000939 -0.043053 -0.082718 -0.101476 0.014253 0.106507 0.059285 -0.034097 0.032848 -0.067852 0.103892 0.020742 -0.049702 0.085734 0.069140 -0.036293 -0.001048 -0.043403 -0.033758 -0.041652 -0.049051 -0.070893 -0.002921 0.096254 -0.046406 -0.016074 0.074894 0.098854 -0.015867 -0.024065 0.048818 -0.058226 -0.031364 0.055631 -0.001012 0.002966 0.017624 0.082472 -0.025849 -0.099736 -0.065253 0.002511 0.026550 -0.046750 0.005665 0.058496 -0.068569 0.110588 -0.003354 -0.133236 -0.140404 0.090284 -0.089065 0.010600 -0.143848 0.023044 0.035726 0.044885 -0.081761 0.020406 0.045142 -0.099682 0.013478 -0.102208 -0.048206 0.040736 0.012733 0.064284 0.052800 0.046179 -0.083605 -0.002064 0.003024 0.078588 -0.075731 -0.038192 -0.010662 -0.062210 -0.060302 0.005740 -0.119290 0.049789 -0.009878 0.033791 0.145393 -0.064118 0.005292 -0.046015 -0.012572 -0.002266 0.018877 -0.114718 0.043831 0.036031 -0.077071 0.079499 0.047130 0.136516 -0.029402 -0.095073 -0.198367 0.077792 -0.092858 -0.115212 0.064883 -0.083748 -0.115535 -0.017903 0.080732 0.088457 0.037072 0.044588 0.042071 0.064027 0.035189 0.071027 -0.028330 0.026847 -0.005846 -0.003655 -0.019447 0.057641 -0.057623 0.032575 -0.009248 0.103035 -0.087592 0.049022 -0.030181 0.055313 0.001550 0.136222 -0.081518 -0.003322 -0.196934 -0.125240 -0.039119 0.082201 -0.036932 -0.030666 0.101376 -0.008224 0.045433 0.055995 -0.108370 0.120019 0.024427 -0.055956 0.076503 -0.063588 -0.091926 -0.047620 0.071838 -0.050062 0.122101 0.011679 0.015549 0.060463 -0.174818 0.006131 -0.035602 -0.039755 0.044683 -0.002324 -0.096353 0.153145 -0.181759 0.059133 0.008242 0.009471 0.004472 -0.005789 0.035746 0.107733 0.019606 0.035323 0.013101 0.078772 0.031495 0.011914 0.035316 0.029965 0.010626 0.024444 -0.036373 0.041982 -0.059195 -0.062521 -0.032445 -0.050086 -0.002740 -0.033702 -0.052157 -0.100889 0.010753 -0.017195 0.076872 -0.114096 -0.134334 0.019812 -0.147168 -0.048026 0.055315 -0.021564 0.092953 -0.070098 -0.009133 -0.021408 -0.043442 -0.059603 -0.026196 -0.046402 -0.024446 0.036482 -0.021195 -0.014285 -0.003113 -0.053620 -0.057722 -0.005912 -0.228597 -0.022520 0.008453 -0.131441 0.074053 0.010990 -0.029988 -0.106588 -0.005512 0.036736 -0.002115 -0.078824 -0.067073 0.034071 -0.037642 0.019106 0.080103 0.068267 -0.052487 -0.070635 0.073949 -0.056421 0.017687 0.011800 -0.014045 0.006226 -0.014210 0.088889 -0.007613 -0.042151 0.091935\n",
            "\n",
            "que 0.105677 -0.012054 -0.134709 -0.013888 -0.080373 -0.084105 0.028820 -0.039461 -0.011410 0.033408 -0.031719 0.198935 0.047353 -0.090613 -0.098891 -0.010202 0.144315 0.151674 0.016502 -0.133896 0.031100 -0.007432 -0.059600 0.059022 -0.038658 0.167877 0.082268 0.217249 -0.072088 0.076910 0.079216 -0.037108 0.014821 -0.078732 -0.035230 0.024507 -0.126809 -0.017172 0.040998 -0.043692 -0.149663 -0.049520 0.024513 -0.063125 0.058306 -0.012108 -0.119330 0.034781 -0.102405 0.088640 -0.272843 -0.059915 -0.108119 -0.004685 0.184494 0.029357 -0.012836 0.087409 -0.093633 0.141491 -0.051050 -0.072004 -0.164353 -0.078488 -0.075351 -0.029836 -0.011346 -0.081588 0.032113 -0.120232 -0.028536 0.010188 0.169394 -0.077409 -0.026955 0.083380 0.010644 0.026978 0.131446 -0.055521 -0.142428 -0.164762 0.016372 -0.254786 -0.015511 -0.044090 -0.091434 0.042059 -0.182369 -0.057621 -0.113482 -0.031757 0.036860 0.035760 -0.084302 -0.244284 0.014317 -0.110019 0.076959 -0.003242 0.058425 -0.068168 -0.150191 -0.054872 0.067636 -0.130009 0.033544 -0.028672 -0.029417 -0.003639 0.008028 0.067533 0.015459 0.057868 -0.095344 0.023596 0.005216 -0.068982 0.110498 -0.045724 0.067068 -0.103614 -0.010749 0.079515 -0.160577 -0.037640 -0.090058 0.194754 -0.137685 0.048330 0.023402 -0.080694 -0.076719 0.081176 0.145217 -0.312484 -0.158713 0.003970 0.017241 0.020559 0.019566 -0.020686 0.027909 -0.088033 0.055311 0.114986 0.046477 -0.026289 -0.085503 0.072325 0.033167 -0.027302 0.043202 -0.125175 -0.046430 -0.089749 -0.052517 -0.026923 -0.157140 0.142859 -0.035472 0.053636 -0.015367 -0.041692 0.004743 -0.053162 -0.073490 -0.031711 0.009967 -0.034655 0.209237 -0.052801 0.121190 -0.048079 0.203458 0.037113 -0.095015 0.143972 0.046959 -0.014909 0.169301 -0.034984 0.006088 -0.180444 -0.098740 -0.082224 0.042493 -0.048264 0.034078 -0.155237 0.049812 0.108571 -0.103458 0.015055 -0.005921 -0.020380 -0.059664 0.063496 0.120677 0.028720 0.010933 -0.034094 -0.033195 0.065065 -0.150067 -0.127015 -0.115948 -0.168308 -0.079605 0.112220 -0.024935 0.008233 -0.050985 -0.047235 -0.041944 0.099358 -0.094031 0.008722 -0.044243 0.091927 0.029639 0.053425 -0.020329 -0.007264 0.029055 -0.027748 0.021123 0.023926 -0.068259 -0.034626 0.010976 -0.027882 0.074465 0.017960 -0.142224 0.010472 -0.005171 0.001003 0.031482 0.048073 0.122005 -0.012546 -0.127375 0.137744 -0.043389 -0.067031 -0.028339 -0.102349 -0.001278 -0.075125 -0.209901 0.022713 0.123317 -0.005108 0.206613 -0.119748 0.148568 0.189863 -0.005551 0.042991 0.024824 0.095960 0.049202 -0.115647 -0.075263 -0.101255 0.047671 0.006936 -0.147872 -0.048649 0.152138 0.090100 -0.054797 0.180955 -0.016752 -0.090723 -0.126502 0.137744 0.065590 -0.095213 -0.141592 -0.081258 0.061414 0.138765 -0.047507 0.155577 -0.004058 -0.054305 -0.064755 -0.155780 0.019290 0.092772 -0.113740 0.062508 -0.108115 -0.104516 0.233178 0.085033 -0.063993 0.107476\n",
            "\n",
            "do -0.180377 0.215497 -0.243985 -0.111583 -0.213779 -0.101028 -0.000539 -0.101256 -0.070914 0.038753 0.046168 -0.014838 0.180611 0.000883 0.060867 0.085324 0.226791 -0.021134 -0.137997 -0.202197 0.148571 -0.050565 -0.078147 -0.128638 -0.060884 0.050100 0.018876 0.214215 0.115665 -0.095654 -0.142162 0.120025 -0.097131 0.072397 -0.038019 0.105100 0.071983 -0.160280 -0.051489 -0.098811 -0.117858 -0.034939 -0.009614 0.107021 -0.047199 -0.005264 -0.000139 0.071706 0.161239 -0.161907 -0.337947 0.006058 0.022506 -0.037415 0.171261 -0.062566 -0.062829 -0.086872 0.049601 0.208633 -0.010851 0.096788 0.242130 -0.103836 -0.078473 -0.008937 -0.192728 0.135349 -0.090459 0.275743 0.134895 0.051969 -0.132400 0.040473 -0.095963 0.027610 0.029590 -0.188700 0.164033 0.032661 -0.109406 0.180492 0.147311 0.025806 -0.079043 -0.050046 0.065651 -0.066955 0.037583 -0.031008 0.012122 -0.225802 0.106807 0.067123 0.035571 -0.204494 -0.004813 -0.022719 -0.267100 0.241056 0.115854 0.094971 -0.032575 0.045279 0.030343 -0.103868 0.013372 0.008258 0.027818 -0.051606 0.060680 0.094947 -0.025672 -0.044170 -0.007713 -0.008499 -0.111320 0.112186 -0.091970 -0.085167 0.001894 0.156088 -0.067075 -0.027825 0.093561 0.070251 0.049796 -0.161722 -0.051384 -0.124694 -0.016951 -0.141747 0.002894 -0.133038 -0.015664 0.080839 -0.090980 0.084050 0.089413 0.021215 0.043560 -0.075679 -0.068300 -0.025250 -0.157061 0.022866 0.055717 -0.019705 0.036159 0.183264 0.073571 -0.227341 -0.020978 0.064482 0.075304 0.010691 -0.068159 0.110613 0.047416 -0.029155 -0.043249 -0.074944 0.011065 -0.047526 0.018594 0.114240 -0.265600 0.007173 -0.118795 -0.109128 0.000016 -0.025266 -0.101829 0.167882 0.163892 -0.112688 -0.195755 -0.162868 0.114179 0.149630 0.075342 0.024940 0.099575 0.154626 0.069327 0.046685 0.046306 -0.138379 0.070196 -0.071198 0.028745 0.052231 -0.034552 -0.065006 0.070413 -0.061854 0.102099 0.063467 -0.002194 0.041076 -0.095035 0.138216 0.123084 -0.022177 0.178009 0.171209 0.193143 -0.170747 0.013212 0.020312 -0.129422 0.079598 -0.068529 -0.147807 0.047131 -0.137531 0.091482 0.030125 0.145402 -0.080191 0.025542 0.178609 0.118927 -0.206678 0.094064 -0.042739 -0.084631 -0.076197 0.253984 -0.273463 -0.026424 0.022400 0.012012 0.061563 0.131845 0.000155 -0.068048 -0.138741 -0.137770 0.143289 -0.017924 -0.111125 -0.055598 -0.012842 0.040329 0.034049 0.148260 -0.121714 -0.091318 0.030290 0.127014 0.037068 -0.070445 -0.136299 -0.232076 -0.028718 0.111683 -0.116630 -0.077730 0.033543 -0.032343 0.091454 0.094135 0.163275 0.123356 0.155053 0.137251 0.054886 0.086155 0.132626 -0.112011 0.103465 -0.085405 -0.075092 0.038307 0.075783 0.028715 0.020250 0.078956 0.012173 -0.058316 0.084967 -0.099896 -0.090466 -0.126150 0.144591 0.025099 0.059846 0.102206 0.092871 -0.004201 -0.062104 0.143311 -0.046741 0.010705 -0.065122 -0.074470 0.072302 0.144289 0.067299\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Construção do modelo Word2Vec a partir do texto ~2 min 44 s\n",
        "from gensim.models import KeyedVectors\n",
        "\n",
        "wv_from_text = KeyedVectors.load_word2vec_format(cbow_300_path)\n",
        "modelo = wv_from_text"
      ],
      "metadata": {
        "id": "tVtl5CgCUP5k",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "963b7572-a1d4-45bb-9d43-eb5c21dfd341"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Vetor de uma palavra\n",
        "vetor_china = modelo.get_vector('china')\n",
        "len(vetor_china)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "ELE87BwLbxdV",
        "outputId": "a72cac1c-3740-4595-9ae7-e8f1fd9eda32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "300"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokens mais próximos de outro token\n",
        "modelo.most_similar('cocaína')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "id": "PPNMz0_tcyD1",
        "outputId": "cb13b010-658e-4f2c-8b87-a4654c784137"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('maconha', 0.7640054225921631),\n",
              " ('haxixe', 0.6427118182182312),\n",
              " ('heroína', 0.6224136352539062),\n",
              " ('crack', 0.6031304001808167),\n",
              " ('droga', 0.5509088635444641),\n",
              " ('marijuana', 0.5143439769744873),\n",
              " ('liamba', 0.510414183139801),\n",
              " ('ecstasy', 0.5004808902740479),\n",
              " ('morfina', 0.48937979340553284),\n",
              " ('metanfetamina', 0.4885428845882416)]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Combinações - Embedding"
      ],
      "metadata": {
        "id": "HU_6BkmfNv0-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# COMBINAÇÃO: Tokens mais próximos de combinação de tokens\n",
        "modelo.most_similar(positive=['brasil', 'argentina'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "id": "6RE8kYvCekIr",
        "outputId": "cbeca5a7-abdb-45c5-8317-1e29cde489aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('chile', 0.6781662702560425),\n",
              " ('peru', 0.6348033547401428),\n",
              " ('venezuela', 0.6273865103721619),\n",
              " ('equador', 0.6037014722824097),\n",
              " ('bolívia', 0.6017140746116638),\n",
              " ('haiti', 0.5993807315826416),\n",
              " ('méxico', 0.5962306261062622),\n",
              " ('paraguai', 0.5957703590393066),\n",
              " ('uruguai', 0.5903672575950623),\n",
              " ('japão', 0.5893509984016418)]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "modelo.most_similar(positive=['frança', 'cocaína'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "id": "jxhCKzo_e2Tu",
        "outputId": "5d42796a-c6f9-4dda-c785-4642b15b023b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('espanha', 0.606521487236023),\n",
              " ('itália', 0.5986364483833313),\n",
              " ('inglaterra', 0.5887600183486938),\n",
              " ('maconha', 0.5859187841415405),\n",
              " ('áustria', 0.5843812227249146),\n",
              " ('suécia', 0.5743238925933838),\n",
              " ('grã-bretanha', 0.5708452463150024),\n",
              " ('holanda', 0.5653262734413147),\n",
              " ('dinamarca', 0.5606917142868042),\n",
              " ('heroína', 0.556676983833313)]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "modelo.most_similar(positive=['bahia', 'pará'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "id": "d8qA-PFBfZqo",
        "outputId": "9e96855b-17fb-48f4-d9cc-196088f1165a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('ceará', 0.7064878940582275),\n",
              " ('paraíba', 0.6952986717224121),\n",
              " ('piauí', 0.6575934290885925),\n",
              " ('paraná', 0.6201068758964539),\n",
              " ('goiás', 0.6155080795288086),\n",
              " ('maranhão', 0.6058744192123413),\n",
              " ('tocantins', 0.6037553548812866),\n",
              " ('acre', 0.5950236916542053),\n",
              " ('amapá', 0.5813421010971069),\n",
              " ('alagoas', 0.5803781747817993)]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Plural"
      ],
      "metadata": {
        "id": "TpGtzPOZf7tT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# nuvens -> nuvem\n",
        "# estrelas -> estrelas\n",
        "\n",
        "# nuvens + estrela - nuvem = estrelas\n",
        "\n",
        "modelo.most_similar(positive=['nuvens', 'estrela'], negative=['nuvem'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "id": "MDWSfTS1f9UV",
        "outputId": "69a1d1a7-b5e6-4c75-c58a-53cc68b285cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('estrelas', 0.5497429966926575),\n",
              " ('plêiades', 0.379197895526886),\n",
              " ('colinas', 0.3746805191040039),\n",
              " ('trovoadas', 0.373703271150589),\n",
              " ('sombras', 0.3734194040298462),\n",
              " ('pombas', 0.3726757764816284),\n",
              " ('corredoras', 0.3640727698802948),\n",
              " ('cigarras', 0.36065393686294556),\n",
              " ('galáxias', 0.35754913091659546),\n",
              " ('luas', 0.3575345277786255)]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Declinação de Gênero"
      ],
      "metadata": {
        "id": "uCevH7GaN-_A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# médico + ela - ele = médica\n",
        "modelo.most_similar(positive=['empresário', 'pesquisadora'], negative=['pesquisador'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "id": "2Vs1apZBgM9H",
        "outputId": "2bd886e5-adb3-43d8-9bf4-a0167ef815de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('empresária', 0.5880690813064575),\n",
              " ('advogada', 0.5456726551055908),\n",
              " ('antropóloga', 0.5085045695304871),\n",
              " ('blogueira', 0.5056331157684326),\n",
              " ('psicóloga', 0.5037093162536621),\n",
              " ('bióloga', 0.48805463314056396),\n",
              " ('cabeleireira', 0.4795725345611572),\n",
              " ('aposentada', 0.47835773229599),\n",
              " ('pedagoga', 0.47171372175216675),\n",
              " ('diarista', 0.4525532126426697)]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# médico + ela - ele = médica\n",
        "modelo.most_similar(positive=['médico', 'pesquisadora'], negative=['pesquisador'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "id": "9BFs0329p6ko",
        "outputId": "35f4db6b-9f84-432d-f2ef-4d170e8b8c35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('psicóloga', 0.572142481803894),\n",
              " ('enfermeira', 0.5531742572784424),\n",
              " ('bióloga', 0.5138505697250366),\n",
              " ('antropóloga', 0.508258044719696),\n",
              " ('nutricionista', 0.49191129207611084),\n",
              " ('advogada', 0.489876925945282),\n",
              " ('socióloga', 0.47331202030181885),\n",
              " ('blogueira', 0.4691736102104187),\n",
              " ('cabeleireira', 0.46026867628097534),\n",
              " ('empresária', 0.44862642884254456)]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Esteriótipos\n",
        "\n",
        "O modelo absorde os esteriótipos da sociedade através das escritas realizadas pela sociedade, pois o modelo não realiza uma análise do sentido das palavras, mas sim o comportamento da escrita humana.\n",
        "\n",
        "> Como discutimos em aula, a inteligência artificial é uma das áreas com maior potencial de transformar o modo como vivemos, da mobilidade à saúde. Com o impulso e progressos da IA nos últimos anos, foi possível o avanço tecnológico dos hardwares e do aumento exponencial de dados disponíveis para treinamento dos modelos de aprendizagem de máquina.\n",
        "\n",
        "> Como os modelos mais promissores na área dependem muito dos dados que produzimos, esses modelos podem reproduzir estereótipos da nossa sociedade, impulsionando ainda mais a desigualdade social. Desenvolver modelos que não reproduzam os aspectos negativos da sociedade e importantíssimo para garantir um futuro mais justo a todos, por isso áreas de pesquisa como ética na IA vem crescendo consideravelmente nos últimos anos.\n",
        "\n",
        "> Gostaria de deixar como recomendação para quem se interessar este [artigo](https://www.weforum.org/agenda/2019/01/ai-isn-t-dangerous-but-human-bias-is/) apresentado no encontro anual do Fórum Económico Mundial, escrito por Richard Socher, cientista chefe da Salesforce, que aborda de maneira muito interessante os perígos envolvidos na reprodutibilidade de estereótipos humanos em sistemas de IA.\n",
        "\n",
        "> Outra ótima referência é o [capítulo 6, seção 6.11 - Bias and Embeddings](https://web.stanford.edu/~jurafsky/slp3/6.pdf), do livro Speech and Language Processing escrito por Dan Jurafsky e James H. Martin. Nesta seção eles abordam o tema viés, além de trazer referências com técnicas para reduzir este problema no embedding de palavras."
      ],
      "metadata": {
        "id": "eqGuFdOVp1cN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Aplicação para o case"
      ],
      "metadata": {
        "id": "GjJBKigr9WKO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As notícias que desejamos classificar são um conjunto de palavras, então é preciso vetorizar essas notícias para que sejam processadas."
      ],
      "metadata": {
        "id": "Wqpz2jOo9Zv-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Análise das frases: possuem acentuação e pontuação\n",
        "artigo_treino['title'].loc[12]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "B2BxkU_E92zO",
        "outputId": "93057bcb-2a91-4309-dc63-a9db9ee50077"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Daniel Craig será stormtrooper em novo 'Star Wars', diz ator\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tokenização\n",
        "\n",
        "O modelo de Word2Vec pre-treinado já passou por um pré-processamento, o que irá impactar no nossos tokens. \n",
        "\n",
        "Por exemplo, palavras raras, como palavras com erro de digitação foram transformadas para `UNKNOWN`. Números foram transformados para `0` ou `00...`. Urls para `URL`. Emails para `EMAIL`."
      ],
      "metadata": {
        "id": "TpGHDVCOFC2P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "O tokenize tem dificuldade de transformar o primeiro aspas simples."
      ],
      "metadata": {
        "id": "pS4X7qYGFS1j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenização - quebra por palavras\n",
        "import nltk\n",
        "import string\n",
        "nltk.download('punkt')\n",
        "\n",
        "def tokenizador(texto, language='pt'):\n",
        "  texto = texto.lower()\n",
        "  lista_alfanumerico = []\n",
        "  pontuacao = string.punctuation\n",
        "\n",
        "  for token in nltk.word_tokenize(texto):\n",
        "    if token in pontuacao:\n",
        "      continue\n",
        "\n",
        "    if language == 'pt':\n",
        "      lista_alfanumerico.append(token.replace(\"'\", ''))\n",
        "\n",
        "  return lista_alfanumerico"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "5qlAybT6-J3m",
        "outputId": "3c815e71-b88c-476d-8219-956d5cb95860"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizador(\"Daniel Craig será stormtrooper em novo 'Star Wars', diz ator\")\n",
        "# tokenizador(\"Yes, I'm right!\")\n",
        "# tokenizador('Ela me disse: \"cara bicho!\"')\n",
        "# \"   'Star Wars'\".strip()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "id": "4sFvRjDJAPWD",
        "outputId": "c5f283e5-e8fb-40d6-962a-d2ee9520cd0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['daniel',\n",
              " 'craig',\n",
              " 'será',\n",
              " 'stormtrooper',\n",
              " 'em',\n",
              " 'novo',\n",
              " 'star',\n",
              " 'wars',\n",
              " 'diz',\n",
              " 'ator']"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Combinando vetores\n",
        "\n",
        "* Média dos vetores de cada palavra\n",
        "* Soma\n",
        "* Combinações com redes neurais\n",
        "\n",
        "* [Técnicas de combinação de vetores](https://www.kaggle.com/c/quora-insincere-questions-classification/discussion/71778)"
      ],
      "metadata": {
        "id": "kcDc5OkcE_fk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def combinacao_de_vetores_soma(palavras_numeros, word2vec_model):\n",
        "  vetor_resultante = np.zeros(300)  # vetor esparso\n",
        "\n",
        "  for pn in palavras_numeros:\n",
        "    # para cada palavra será adicionado ao vetor combinado os valores do Word2Vec(300)\n",
        "    try:\n",
        "      vetor_resultante += word2vec_model.get_vector(pn)\n",
        "    except KeyError:\n",
        "      if pn.isnumeric():\n",
        "        pn = '0' * len(pn)\n",
        "        vetor_resultante += word2vec_model.get_vector(pn)\n",
        "      elif '@' in pn:\n",
        "        pn = 'EMAIL'\n",
        "        vetor_resultante += word2vec_model.get_vector(pn)\n",
        "      elif 'http' in pn:\n",
        "        pn = 'URL'\n",
        "        vetor_resultante += word2vec_model.get_vector(pn)\n",
        "      else:\n",
        "        pn = 'unknown'\n",
        "        vetor_resultante += word2vec_model.get_vector(pn)\n",
        "\n",
        "  return vetor_resultante"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "dfpqjnvUAa7x",
        "outputId": "140b34c3-f8cc-4978-d304-4ff7155d8193"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "palavras_numeros = tokenizador('texto 55 email@meu.com textosss')\n",
        "vetor_texto = combinacao_de_vetores_soma(palavras_numeros, word2vec_model=modelo)\n",
        "vetor_texto"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "nDJSQ7K7Jo58",
        "outputId": "71599d12-47b6-4f15-f16f-262b2bd3e8fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.71333102,  0.233138  , -0.262831  ,  0.40465299,  0.08968799,\n",
              "       -0.12859901,  0.36422   ,  0.06705298, -0.42137901,  0.22912   ,\n",
              "        0.20574899, -0.422199  , -1.00184998,  0.79917402,  0.083206  ,\n",
              "        0.41008801, -1.40153898, -0.21416499, -0.62434299, -0.59793197,\n",
              "       -0.105193  , -0.206048  ,  0.036963  ,  1.22250398, -0.40927802,\n",
              "       -0.015125  , -0.61525903,  0.14933401,  0.22086101, -0.47592898,\n",
              "       -0.65150899,  0.059235  ,  0.380605  , -0.31868899,  0.46247097,\n",
              "        0.409421  ,  0.84811502,  0.25158099,  0.37866702,  0.30965401,\n",
              "        0.071924  , -0.00541399,  0.49063899,  0.29510101,  0.76056498,\n",
              "       -0.19310001,  0.861871  ,  0.73134004,  0.889483  ,  0.73041601,\n",
              "        0.6921    , -0.01101   , -0.17228799,  0.280772  ,  0.48982001,\n",
              "       -0.29811899, -0.17408902,  0.806493  , -0.149249  , -0.221432  ,\n",
              "       -0.13051602,  0.62860796,  0.35374498, -0.606888  ,  0.393793  ,\n",
              "        0.102797  ,  0.92551997, -0.010614  ,  0.73485998, -0.355691  ,\n",
              "        0.655771  , -1.22992902,  0.5134    , -0.07965798, -0.34047199,\n",
              "        0.188064  , -0.43745501, -0.098819  ,  0.02930599, -0.346836  ,\n",
              "       -0.85307299,  0.135753  ,  1.41644301, -0.272595  , -0.273178  ,\n",
              "       -0.496705  , -1.13301397,  0.63430899,  0.66388002, -0.49314199,\n",
              "        0.09465401,  0.09743499, -0.302755  ,  0.05107901,  0.01586299,\n",
              "        0.804425  , -0.03535   , -0.07155401,  0.26147301, -0.82647499,\n",
              "        0.374738  , -0.33316401,  0.25581099,  0.05425   ,  0.62996999,\n",
              "        0.60084299, -0.38464098,  0.56133902, -0.638972  ,  0.373875  ,\n",
              "        0.056199  ,  0.201891  ,  0.416242  ,  0.18182   ,  0.145865  ,\n",
              "       -0.00510202,  0.13765102,  0.03753497,  0.48057401, -0.20767799,\n",
              "        0.78331099, -0.86532101,  0.020445  , -0.20327696,  0.05933401,\n",
              "       -0.86363802, -0.48231899,  0.46134   , -0.52152199,  0.23789899,\n",
              "       -0.458883  ,  0.68707098, -0.34727499,  0.08592002,  0.36225098,\n",
              "       -0.55961901,  0.194681  ,  0.079162  ,  0.67850499,  0.21502299,\n",
              "       -0.27334798, -0.066028  ,  0.034893  ,  0.69587302, -0.39716199,\n",
              "        0.626305  ,  0.23617   , -0.06377701,  1.63428302, -0.182339  ,\n",
              "       -0.38238899,  0.46186101, -0.08544897, -0.236145  , -0.175246  ,\n",
              "        0.113908  ,  0.67258903,  0.283942  ,  0.66928098,  0.044877  ,\n",
              "        0.82169798,  0.100066  ,  0.004584  , -0.57448401, -0.26872601,\n",
              "       -0.03027401,  0.59016599,  0.02583201, -0.051505  ,  0.39175199,\n",
              "       -0.77008302, -0.04132299,  0.042539  , -0.128429  , -1.02719402,\n",
              "       -0.391905  ,  0.71522398, -0.30433   , -0.439415  , -0.70026299,\n",
              "       -0.57367301, -0.099645  , -0.39504901, -0.29317301,  0.64083102,\n",
              "       -0.75884398,  0.61624902,  0.377777  , -1.14034599, -0.15034603,\n",
              "       -0.03607   ,  0.19184901, -0.51428401,  0.68958101,  0.30691301,\n",
              "        1.30818399, -0.41604899, -0.72406199,  0.57406499,  0.212779  ,\n",
              "       -0.88058901,  0.216946  ,  0.071918  , -0.003132  , -0.294043  ,\n",
              "       -0.18569401, -0.08348799,  0.05759797,  0.59548095,  0.93658396,\n",
              "        0.55101702,  0.24656401,  0.73254502, -0.47753798, -0.14840701,\n",
              "        0.11076599,  0.77467299, -0.13802501, -0.31102501,  0.33112101,\n",
              "       -0.48217401,  0.24703   , -0.795221  , -0.356844  ,  0.734935  ,\n",
              "        0.58334102, -0.22942   , -0.31601399,  0.388167  , -0.297911  ,\n",
              "       -0.166332  , -0.296278  , -0.21899801, -0.38738101, -0.79757399,\n",
              "       -0.25202998, -0.827737  ,  0.471516  , -0.513631  , -0.580618  ,\n",
              "        0.12207099,  0.377275  ,  0.97140601, -0.44109   ,  0.68253201,\n",
              "        0.309582  ,  0.47706401,  0.457719  ,  0.547182  , -0.09613499,\n",
              "        0.05284101,  0.21391201,  0.235272  , -0.40287899,  0.13463499,\n",
              "        1.06466298,  0.77317702, -0.20682499,  0.856119  , -0.420781  ,\n",
              "        0.29997102,  0.194104  ,  0.07547301, -0.13193698,  0.18672501,\n",
              "       -0.233266  ,  0.67896001, -0.197005  ,  0.54254199, -0.74823498,\n",
              "       -0.13459697,  0.03074001,  0.85251098,  0.80378102, -0.418276  ,\n",
              "       -0.33818103,  0.374647  ,  0.06242498,  0.106637  , -0.77469999,\n",
              "       -0.827458  , -0.422165  ,  0.186904  ,  0.239375  ,  0.026479  ,\n",
              "       -0.51885899, -0.03363899, -1.24842   , -1.17899401, -1.39049099,\n",
              "        1.371349  ,  0.19853999, -0.06610101, -0.342702  ,  0.16170201,\n",
              "        0.97404901, -0.05563499, -0.62624201,  0.34367901,  1.99428305])"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "modelo.get_vector('unknown')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0YqyGZ4mJzQh",
        "outputId": "f97a8726-fe20-45fc-d4cd-e9e38c3b8887"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 3.54566e-01, -5.48110e-02, -3.84400e-02,  1.24058e-01,\n",
              "       -8.06360e-02,  5.91960e-02,  2.04200e-02, -1.78659e-01,\n",
              "       -1.81335e-01, -9.11180e-02, -4.57600e-02, -1.06127e-01,\n",
              "       -4.01736e-01,  4.19984e-01, -3.33250e-02,  1.77705e-01,\n",
              "       -5.43387e-01, -8.51910e-02, -5.33234e-01, -2.86099e-01,\n",
              "        3.33630e-02, -1.85811e-01,  6.87260e-02,  5.20180e-01,\n",
              "       -2.98402e-01, -3.23700e-02, -2.72469e-01, -9.92270e-02,\n",
              "        1.96912e-01, -1.82213e-01, -3.08074e-01, -3.69640e-02,\n",
              "        9.03970e-02,  4.04880e-02, -6.46750e-02,  4.37740e-02,\n",
              "        8.93440e-02, -4.98380e-02,  1.37664e-01, -1.27749e-01,\n",
              "       -1.14070e-02, -1.04679e-01, -1.39191e-01, -5.21400e-03,\n",
              "        2.90866e-01, -9.60230e-02,  2.38736e-01,  3.26503e-01,\n",
              "        3.30080e-01,  2.03619e-01,  9.67800e-03,  1.19000e-01,\n",
              "       -1.79310e-02,  1.29586e-01,  3.19442e-01, -1.05512e-01,\n",
              "        9.31870e-02,  1.40411e-01,  5.84020e-02,  5.88410e-02,\n",
              "        1.11957e-01,  4.73554e-01,  2.45136e-01, -5.09600e-03,\n",
              "       -5.26140e-02, -1.60310e-02,  2.97038e-01,  7.49760e-02,\n",
              "        3.71848e-01, -1.69017e-01,  2.00654e-01, -2.82788e-01,\n",
              "        1.90314e-01, -1.79972e-01, -2.16299e-01, -3.66670e-02,\n",
              "       -1.69905e-01, -7.02750e-02,  5.86860e-02,  9.41790e-02,\n",
              "       -3.03166e-01,  1.52841e-01,  3.96487e-01, -2.16211e-01,\n",
              "       -2.30948e-01,  1.76833e-01, -2.94953e-01,  2.90743e-01,\n",
              "        3.21565e-01, -1.10768e-01,  1.07695e-01, -1.21356e-01,\n",
              "       -1.07924e-01, -1.36235e-01,  2.10177e-01,  2.14678e-01,\n",
              "        1.02345e-01, -1.94468e-01,  3.69220e-02, -1.38605e-01,\n",
              "        1.25925e-01, -1.18518e-01,  2.53088e-01, -3.41490e-02,\n",
              "        1.95908e-01,  1.66225e-01, -2.19360e-02,  2.14925e-01,\n",
              "       -3.28731e-01,  1.92627e-01, -1.08048e-01, -1.42030e-02,\n",
              "        2.33410e-02, -1.83589e-01, -6.16500e-03,  1.71897e-01,\n",
              "        2.09809e-01, -1.68758e-01,  1.97822e-01, -1.63032e-01,\n",
              "        1.29052e-01, -2.31592e-01, -1.21770e-01, -3.20758e-01,\n",
              "       -1.06521e-01, -3.31555e-01, -1.86696e-01,  5.83900e-03,\n",
              "       -1.25445e-01,  8.30070e-02, -1.87665e-01,  2.83092e-01,\n",
              "        2.14400e-03, -9.70990e-02,  1.92336e-01, -4.62000e-04,\n",
              "       -6.87670e-02,  1.26588e-01,  2.30264e-01,  1.68407e-01,\n",
              "       -2.34021e-01, -1.83542e-01,  2.25696e-01, -3.68550e-02,\n",
              "       -2.02355e-01,  1.16067e-01, -9.66530e-02, -9.37850e-02,\n",
              "        5.52338e-01, -2.08050e-02, -2.22657e-01, -3.91590e-02,\n",
              "       -2.71614e-01, -8.88850e-02, -1.10371e-01,  2.30076e-01,\n",
              "        3.12234e-01, -2.49440e-02,  3.63508e-01,  9.97640e-02,\n",
              "        9.94400e-02,  1.98137e-01, -4.53620e-02, -1.63312e-01,\n",
              "        4.59920e-02,  2.24835e-01,  8.87030e-02,  1.63012e-01,\n",
              "        8.39580e-02,  4.94900e-02,  1.05920e-01,  7.74480e-02,\n",
              "        7.22790e-02,  2.77470e-02, -3.41775e-01, -8.43880e-02,\n",
              "        2.13260e-01, -1.92344e-01, -1.35048e-01, -4.14206e-01,\n",
              "       -2.51764e-01,  1.40755e-01, -3.79117e-01, -1.80414e-01,\n",
              "        4.49445e-01, -2.55424e-01,  4.32734e-01,  7.38940e-02,\n",
              "       -3.63520e-01, -2.80066e-01, -7.78670e-02, -1.82440e-02,\n",
              "       -2.60580e-01,  2.27878e-01,  3.61910e-02,  4.19251e-01,\n",
              "       -5.65530e-02, -4.52800e-02,  9.51750e-02,  6.36280e-02,\n",
              "       -4.48832e-01,  1.04230e-02,  1.75191e-01,  9.58800e-03,\n",
              "        8.94100e-03,  7.20470e-02,  6.14360e-02, -2.97154e-01,\n",
              "        5.18065e-01,  2.76657e-01, -4.48700e-02,  9.15540e-02,\n",
              "        2.80555e-01,  5.35000e-04,  1.56200e-02,  3.23020e-02,\n",
              "        3.95104e-01,  7.96330e-02, -6.44000e-03, -1.32705e-01,\n",
              "       -1.68815e-01,  9.28090e-02, -2.97701e-01, -2.08200e-01,\n",
              "        1.17750e-02,  3.04437e-01, -1.47470e-01, -4.27560e-02,\n",
              "        1.65153e-01, -7.48640e-02, -5.39390e-02, -1.89036e-01,\n",
              "        5.28290e-02,  1.70170e-02, -3.30300e-02,  7.20800e-02,\n",
              "       -1.76892e-01,  1.28343e-01, -1.15538e-01, -1.55221e-01,\n",
              "       -6.47630e-02,  1.75003e-01,  1.79352e-01,  1.14050e-02,\n",
              "        4.72664e-01,  4.63285e-01,  1.77089e-01,  1.93433e-01,\n",
              "        3.03830e-01, -8.25440e-02,  8.65560e-02,  6.62020e-02,\n",
              "        2.77100e-03, -2.33433e-01,  6.21270e-02,  2.83036e-01,\n",
              "       -6.50200e-03,  1.18987e-01,  1.97000e-01,  4.28190e-02,\n",
              "        2.08872e-01,  9.91100e-02,  1.20883e-01,  2.65489e-01,\n",
              "        1.47170e-01, -3.70090e-02,  8.58440e-02, -7.04600e-03,\n",
              "        1.95963e-01,  1.04750e-02, -3.04754e-01, -6.90010e-02,\n",
              "        3.40596e-01,  3.01647e-01, -2.98529e-01,  2.04768e-01,\n",
              "        2.13634e-01,  1.81403e-01,  6.20400e-02, -4.57997e-01,\n",
              "       -5.97951e-01, -2.56535e-01,  1.64777e-01,  2.45230e-02,\n",
              "       -9.61890e-02, -1.32140e-01, -1.84682e-01,  1.64890e-02,\n",
              "       -3.14385e-01, -3.48274e-01,  2.41313e-01, -7.74030e-02,\n",
              "       -1.39216e-01,  5.39330e-02, -2.88890e-02,  6.93920e-02,\n",
              "       -1.62646e-01, -3.18125e-01,  2.47728e-01,  6.54519e-01],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Vetorização dos Artigos"
      ],
      "metadata": {
        "id": "623Tf-quP_-n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Treino\n",
        "len(artigo_treino)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "OISNu0m6GNbM",
        "outputId": "de29d5df-e1bd-486e-8694-1535eccae849"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "90000"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Treino\n",
        "len(artigo_teste)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "j8l7JagLQG6A",
        "outputId": "d951de66-6ef9-4a03-815c-0d37af4a4492"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20513"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Função de vetorização de todos os textos\n",
        "def matriz_vetores(textos, word2vec_model):\n",
        "  x = len(textos)\n",
        "  y = 300  # representação Word2Vec\n",
        "  matriz = np.zeros((x,y))\n",
        "\n",
        "  for i in range(x):\n",
        "    palavras_numeros = tokenizador(textos.iloc[i])\n",
        "    matriz[i] = combinacao_de_vetores_soma(palavras_numeros, word2vec_model=word2vec_model)\n",
        "\n",
        "  return matriz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "z_HQEbMlQIyu",
        "outputId": "d242baf6-1e2d-4051-d428-b2605ec02277"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Vetorização dos títulos\n",
        "matriz_vetores_treino = matriz_vetores(artigo_treino['title'], modelo)\n",
        "matriz_vetores_teste = matriz_vetores(artigo_teste['title'], modelo)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "nF1SE_mrRJ4e",
        "outputId": "13a33d2b-b8bf-4961-98b1-ce55859d0760"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(matriz_vetores_treino.shape)\n",
        "print(matriz_vetores_teste.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "11yDJO19RhWJ",
        "outputId": "79aaf677-4c06-4599-c2f6-e411e56410ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(90000, 300)\n",
            "(20513, 300)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Classificação\n",
        "\n",
        "* Classificação multinomial\n",
        "\n",
        "SAIBA MAIS\n",
        "\n",
        "* [Regressão Logística](https://www.youtube.com/watch?v=yIYKR4sgzI8)\n",
        "* "
      ],
      "metadata": {
        "id": "Tjhm2LemTjDI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "LR = LogisticRegression(max_iter=200)\n",
        "LR.fit(matriz_vetores_treino, artigo_treino['category'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "PCbE2j-HTloS",
        "outputId": "a5ca61f3-8a8c-4e4b-eb94-8983bf171303"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(max_iter=200)"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Quantas iterações foram necessárias para convergir?\n",
        "LR.n_iter_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "aSS2HvaaU-UF",
        "outputId": "32f5bf80-825e-4d22-e390-0c48145e6dd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([121], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Avaliação do modelo"
      ],
      "metadata": {
        "id": "XjR-1UTkVlxI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Acurácia do treino\n",
        "LR.score(matriz_vetores_treino, artigo_treino['category'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "ZPxp-8-zVLZf",
        "outputId": "89676e91-d91b-4396-8015-589b91fd26bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8164888888888889"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Acurácia do teste\n",
        "LR.score(matriz_vetores_teste, artigo_teste['category'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "_0rFPTUFVTnH",
        "outputId": "d29c72a7-8d2d-469b-d445-870ebbcb20e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7978842685126505"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predição nos testes\n",
        "LR.predict(matriz_vetores_teste)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "iWVME146T8as",
        "outputId": "ba9023b0-0088-49a8-8637-39b0e6e5ee8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['colunas', 'cotidiano', 'esporte', ..., 'mercado', 'colunas',\n",
              "       'mundo'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "artigo_treino['category'].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "HQdxSL90Vgk2",
        "outputId": "44a98fc4-4be5-4241-d750-0af2c221074a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['mundo', 'cotidiano', 'mercado', 'esporte', 'ilustrada', 'colunas'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Interpretando a classificação: Avaliação por categoria\n",
        "\n",
        "**Precisão (precision)** mostra a quantidade de classes classificadas corretamente sobre tudo que foi classificado como aquela classe, ou seja, é a quantidade de verdadeiro-positivo sobre a soma verdadeiro-positivo + falso-positivo. \n",
        "\n",
        "Já a **revogação (recall)** é tudo que foi classificado corretamente sobre o total daquela classe, ou seja, é a quantidade de verdadeiro-positivo sobre verdadeiro-positivo + falso-negativos. Então, revogação mostra a capacidade de recuperar classes relevantes, enquanto precisão mostra o quão bem estas classes são recuperadas.\n",
        "\n",
        "\n",
        "> Na matemática, a média harmônica geralmente é utilizada em situações em que a média de taxas é desejada. Ver vídeo [sobre média harmônica](https://www.youtube.com/watch?v=bamPhPrZk6w).\n",
        "\n",
        "* [Conteúdo sobre as métricas](https://scikit-learn.org/stable/modules/model_evaluation.html#model-evaluation)"
      ],
      "metadata": {
        "id": "kBD8SMVAVn3U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "\n",
        "CR = classification_report(\n",
        "    y_true=artigo_teste['category'], \n",
        "    y_pred=LR.predict(matriz_vetores_teste))\n",
        "print(CR)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "id": "WcNsEzA2Vq0g",
        "outputId": "ce0855b8-ef43-4ada-dcaf-ef02e6024b6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     colunas       0.86      0.72      0.78      6103\n",
            "   cotidiano       0.61      0.80      0.69      1698\n",
            "     esporte       0.92      0.88      0.90      4663\n",
            "   ilustrada       0.14      0.89      0.24       131\n",
            "     mercado       0.84      0.79      0.82      5867\n",
            "       mundo       0.74      0.86      0.79      2051\n",
            "\n",
            "    accuracy                           0.80     20513\n",
            "   macro avg       0.69      0.82      0.70     20513\n",
            "weighted avg       0.83      0.80      0.81     20513\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Baseline: Dummy Classifier\n",
        "\n",
        "Como saber se o nosso modelo é bom ou não? Não temos nenhuma referência para comparar.\n",
        "\n",
        "[sklearn.dummy.DummyClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.dummy.DummyClassifier.html)"
      ],
      "metadata": {
        "id": "WSKsyf1v53MC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.dummy import DummyClassifier\n",
        "\n",
        "DC = DummyClassifier(strategy='stratified')\n",
        "DC.fit(matriz_vetores_treino, artigo_treino['category'])\n",
        "label_previsao_dc = DC.predict(matriz_vetores_teste)\n",
        "\n",
        "CR_dummy = classification_report(\n",
        "    y_true=artigo_teste['category'], \n",
        "    y_pred=label_previsao_dc)\n",
        "print(CR_dummy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "id": "O1IqnMTx56sA",
        "outputId": "f8c642e9-2c14-4f2b-cc04-e19e5d6f02ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     colunas       0.30      0.17      0.21      6103\n",
            "   cotidiano       0.08      0.15      0.10      1698\n",
            "     esporte       0.23      0.18      0.20      4663\n",
            "   ilustrada       0.01      0.21      0.02       131\n",
            "     mercado       0.29      0.17      0.21      5867\n",
            "       mundo       0.10      0.17      0.13      2051\n",
            "\n",
            "    accuracy                           0.17     20513\n",
            "   macro avg       0.17      0.17      0.14     20513\n",
            "weighted avg       0.24      0.17      0.19     20513\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Skip-Gram"
      ],
      "metadata": {
        "id": "1DqcZ9An8va2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "uri_skipgram_300 = 'https://caelum-online-public.s3.amazonaws.com/1638-word-embedding/skip_s300.zip'\n",
        "\n",
        "!wget $uri_skipgram_300\n",
        "!unzip skip_s300.zip\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "vyOr4jrh6ouh",
        "outputId": "a3c30286-b794-4fc8-915d-8c7a9763b32a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  skip_s300.zip\n",
            "  inflating: skip_s300.txt           \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Leitura do arquivo de tokens\n",
        "path_skipgram_300 = '/content/skip_s300.txt'\n",
        "\n",
        "with open(path_skipgram_300) as file:\n",
        "  for linha in range(5):\n",
        "    print(next(file))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "63b63851-8fa7-476c-984a-c19171f85acb",
        "id": "lWlotcAO9K45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "929606 300\n",
            "\n",
            "</s> -0.001667 -0.000158 -0.000026 0.001300 -0.000796 0.001527 0.000046 0.000584 0.000449 -0.000100 0.000353 0.001251 0.001069 0.000506 0.000574 0.000838 -0.000930 -0.001220 0.000317 0.001315 -0.001120 0.001373 -0.000040 -0.001580 0.000421 -0.000667 -0.001556 -0.000746 0.001604 0.001157 -0.000027 0.000354 0.000358 -0.000527 -0.000573 -0.001512 -0.001557 -0.001637 0.001617 -0.001511 -0.001022 -0.001426 0.001086 -0.001033 0.000593 0.000724 0.000627 -0.000450 -0.001140 0.000333 0.000524 0.001541 0.000284 0.000617 -0.000807 -0.000088 -0.000364 0.001126 -0.001230 -0.001138 -0.001280 0.001330 0.001257 0.000576 0.000764 0.000684 0.001008 -0.000215 -0.000629 -0.001228 -0.001557 -0.000311 -0.000246 0.000045 0.001136 -0.000645 -0.000549 0.001099 0.000858 -0.000886 0.000553 0.000303 0.001433 0.000732 0.001321 -0.000894 -0.000700 -0.000661 -0.001484 -0.000950 -0.001556 -0.000809 0.000348 -0.000068 0.000724 -0.000569 -0.000161 -0.001628 -0.001437 -0.000259 -0.000296 -0.001571 0.000149 0.000847 0.000613 0.000802 0.001507 0.001015 0.000377 0.000255 -0.000458 -0.000777 -0.001561 0.001601 -0.001520 -0.001210 0.000106 0.000714 0.000392 0.001311 -0.001192 -0.000090 -0.001097 0.000424 -0.000954 -0.001272 -0.001178 0.000036 -0.000181 0.000331 -0.001453 -0.001488 -0.001033 -0.000377 0.000257 -0.001418 0.001109 0.000722 0.000936 -0.000113 0.001215 -0.000263 0.000652 0.001190 -0.000258 0.001391 0.001213 0.000783 -0.001202 0.000470 -0.000879 0.000688 -0.001163 -0.001105 0.001497 0.001304 -0.001322 -0.001501 0.001377 0.001439 0.000884 0.000484 0.001239 -0.001578 0.000981 -0.000318 -0.001180 -0.001375 -0.001491 0.001057 -0.001028 0.000893 0.001028 0.000772 0.001636 -0.000331 -0.000247 -0.001006 -0.000329 0.000837 0.000605 -0.000959 0.001410 0.000488 0.001167 -0.000293 -0.001188 -0.000001 0.001135 0.001141 0.001504 0.000198 -0.001060 0.001551 -0.000003 -0.001474 -0.000391 -0.000880 0.000433 -0.000976 -0.001417 0.000563 -0.001188 0.000593 0.001584 -0.001602 -0.000439 -0.001148 -0.001256 0.001185 -0.000738 0.001543 -0.000846 -0.001029 -0.000641 -0.001587 0.001439 -0.001251 0.000942 -0.001414 -0.001106 0.001087 -0.000027 0.000757 -0.000159 -0.001014 -0.000891 0.000024 -0.000238 0.000157 -0.001067 0.000902 -0.001050 -0.000428 -0.001606 -0.000988 0.001391 0.001165 -0.000113 -0.001000 -0.000055 -0.001369 0.000684 0.000715 0.001407 0.000613 0.001389 0.001315 -0.000130 -0.001044 0.000175 -0.000035 0.000959 -0.000345 0.001209 -0.001251 -0.001219 0.001231 -0.000996 -0.001388 0.001038 0.001336 -0.001066 -0.000881 -0.001066 -0.001466 -0.000274 0.000201 0.000401 0.000132 0.000588 0.000589 -0.000128 0.001073 0.001197 0.000109 0.000770 0.001221 0.000996 -0.001174 0.000135 -0.001134 -0.001385 -0.000311 -0.001631 -0.000564 0.001162 -0.000322 -0.000469 0.001312 -0.001402 0.000239 0.000184 0.001300 0.000021 -0.001065 0.000047 -0.000301 0.001336 0.000332\n",
            "\n",
            ", -0.093682 -0.070700 -0.138648 -0.037493 -0.029906 0.004536 0.028511 0.061820 0.099130 -0.049269 -0.108946 -0.032305 0.012313 -0.113740 0.067139 -0.056363 -0.031247 -0.030511 0.159621 0.066568 -0.033371 -0.028255 0.055037 -0.063571 -0.004225 0.113623 0.046277 -0.103895 -0.012220 -0.006329 -0.144638 0.072964 0.091321 0.050717 0.002146 -0.006751 -0.132076 0.033892 0.046169 -0.053418 0.019702 0.032402 0.155613 -0.054440 0.094808 -0.151209 0.067505 0.079562 -0.099358 0.033915 -0.160241 -0.031881 -0.087031 -0.034187 0.067176 -0.060740 0.023628 0.042079 0.024629 0.124291 0.026058 0.141246 0.029661 0.053267 -0.008235 -0.000972 0.056583 -0.191990 0.065576 -0.015714 0.060275 0.033739 -0.112057 0.083519 0.039184 0.035328 0.021722 -0.003323 0.047742 0.046596 0.049122 -0.043080 0.009209 0.002570 0.009096 0.276390 0.074748 -0.048393 -0.092431 0.157569 0.091482 0.042078 -0.092715 0.050437 0.071957 0.055932 0.178105 -0.045652 0.045890 -0.069964 0.098816 -0.082218 0.119355 -0.004237 -0.025380 -0.089383 -0.099893 -0.088295 0.014198 0.052013 -0.066107 0.086473 -0.078195 -0.020723 -0.131519 0.003568 -0.062811 0.172996 -0.058904 0.064825 0.030902 0.006654 -0.030633 -0.071441 -0.056093 0.004357 -0.050868 -0.015273 0.078664 -0.098928 0.091035 -0.085938 -0.052388 0.087729 -0.035346 -0.046271 0.020456 0.038868 0.117081 -0.062649 -0.024919 0.040951 0.033896 0.000936 -0.059150 -0.038884 -0.090511 0.064984 0.057379 -0.008894 0.057960 -0.001119 -0.004897 -0.010969 -0.133347 0.050251 -0.057934 -0.048015 -0.010093 -0.005733 -0.002795 0.006790 0.051303 -0.060995 0.014631 -0.024863 -0.199191 -0.179256 -0.122275 -0.128821 -0.086376 -0.004165 0.071188 -0.157054 -0.002065 -0.071287 0.014880 -0.051518 -0.039903 0.053116 -0.013904 -0.010461 -0.006511 0.001343 0.021601 0.018282 0.022335 -0.118921 0.064224 0.003330 -0.165646 -0.044236 0.109706 -0.030002 -0.056104 0.066319 0.038369 0.005933 -0.027602 -0.028762 0.142961 -0.010216 0.103487 0.032544 -0.063415 -0.019918 -0.005969 0.006451 0.102619 -0.056159 -0.009431 -0.056883 -0.132064 0.124845 -0.095689 0.036106 -0.050677 0.058103 -0.026395 0.066707 -0.012428 -0.005024 0.094513 0.052633 0.115137 0.055586 -0.081150 0.069882 0.084735 -0.042359 0.027782 0.178453 -0.140130 -0.056544 -0.146597 -0.176081 -0.051487 -0.153843 0.010518 0.078492 -0.068070 0.114950 -0.021597 -0.003065 -0.187886 -0.072289 -0.162904 -0.044718 -0.005059 -0.119852 0.129167 -0.001394 -0.100323 -0.087085 0.035399 0.138097 -0.132221 0.047480 -0.032471 0.184572 -0.037331 0.045775 -0.083778 -0.022169 -0.113891 -0.147877 0.120088 -0.019519 -0.012284 -0.036723 -0.055743 -0.006194 -0.029531 0.040442 -0.098426 0.029735 0.050369 -0.009356 0.063697 0.053175 -0.062907 -0.015365 -0.063385 0.061609 0.108089 0.118303 0.034862 0.061621 0.023340 -0.055828 0.019932 0.031650 -0.091759 -0.093564 0.068284 0.060915 0.094451 0.058931 -0.001189 -0.097295\n",
            "\n",
            "de -0.103755 0.070214 -0.018556 -0.009372 0.014126 -0.028314 0.218032 -0.110365 0.143496 -0.110092 -0.073397 0.085151 0.114330 0.047626 0.024120 -0.093889 0.051616 0.088114 0.190179 -0.044876 0.065351 -0.101532 0.061584 -0.055956 0.140648 -0.131240 0.086771 0.009063 0.036474 -0.060591 -0.060941 -0.048905 0.040345 0.133413 -0.089074 0.059441 0.002684 0.101992 0.040317 -0.089481 0.041699 -0.059536 -0.023455 -0.034694 0.050703 -0.065204 0.094124 0.151450 -0.054738 0.010010 -0.084991 0.010247 -0.029547 -0.098366 0.071755 -0.030382 0.002591 0.143181 0.142739 0.143250 -0.116110 0.169506 0.019997 0.128485 -0.042984 0.085598 0.094139 -0.088975 0.164149 -0.045631 0.052231 0.027144 -0.072443 0.107948 0.021743 0.030963 0.120919 -0.027114 0.187965 -0.069237 -0.058527 -0.089989 0.041979 0.039381 -0.058543 0.328083 0.152212 0.024223 -0.002875 0.136757 0.116663 0.092446 -0.110576 0.075501 0.073597 0.155147 0.095693 0.003894 0.070283 0.053220 0.161170 -0.103379 -0.017995 -0.009784 0.010043 -0.124172 -0.064448 -0.085754 -0.057013 0.073941 -0.140396 -0.056482 -0.132458 0.053426 -0.103984 0.076254 -0.057169 0.187657 -0.047642 0.066818 -0.039731 0.030493 0.066953 -0.075457 -0.061620 -0.168872 -0.066023 0.005682 0.024374 0.041656 0.086353 0.076664 -0.048222 0.017902 -0.038834 -0.115390 -0.051334 0.129188 0.066013 -0.065634 -0.050786 -0.008565 0.050700 0.150692 0.048594 -0.002750 -0.084458 -0.033638 0.114600 0.088278 0.024915 -0.079596 0.026130 -0.093485 -0.074759 -0.079987 -0.160219 0.081674 0.091696 0.029976 0.040177 -0.082989 0.035512 -0.006703 -0.108014 -0.119395 -0.073821 -0.177447 0.019972 -0.122505 -0.140300 0.087286 0.166430 -0.034856 0.027188 -0.047150 -0.118549 -0.065175 -0.043384 0.088207 -0.037209 -0.029710 0.037603 0.119133 -0.061386 0.060832 -0.075209 -0.135386 0.041816 -0.078221 -0.170549 0.018669 -0.029029 -0.143492 -0.044211 0.049634 0.147363 -0.111244 0.059436 -0.094031 0.076651 -0.067966 0.110338 -0.033924 0.094910 -0.051278 -0.038115 -0.033163 0.023708 -0.041563 -0.038060 0.005486 -0.074859 0.123887 -0.049004 -0.001083 0.013151 0.131433 -0.227748 0.047560 0.089538 0.039501 -0.031401 0.098999 0.154208 -0.004613 0.027700 0.050476 0.144603 0.012692 -0.099826 0.091430 -0.042295 -0.082707 -0.090771 -0.206894 -0.073735 -0.006637 0.013339 0.104845 -0.011947 0.127443 0.011430 0.034350 -0.228094 -0.035224 -0.001956 0.010601 -0.001122 0.001234 0.021905 -0.111338 0.029691 0.033142 -0.033792 0.185074 -0.079238 0.083118 -0.116152 0.075778 -0.032638 -0.004429 -0.152247 -0.038457 -0.076691 0.132325 0.077295 -0.092435 0.122214 -0.024088 0.003832 0.029211 -0.062102 0.048037 -0.041055 0.046133 0.092534 0.029173 0.042454 -0.163312 -0.066916 -0.088079 -0.161606 0.087393 0.007666 0.090169 0.064914 0.031613 -0.096452 -0.019126 -0.081154 0.092865 -0.033444 -0.010553 0.001741 -0.011290 -0.037109 0.043787 0.072865 -0.100664\n",
            "\n",
            ". -0.232425 -0.067750 -0.238036 -0.115604 0.043800 0.053748 0.081770 -0.031680 0.081185 -0.086263 -0.138222 0.016832 0.116452 -0.138407 0.010719 -0.140084 -0.132405 -0.082338 0.073210 0.107378 -0.047115 -0.087661 -0.015998 -0.035996 -0.009270 -0.022754 0.100875 -0.005277 -0.177138 -0.160839 0.011583 0.070592 0.069588 -0.056906 0.035837 -0.001398 -0.155866 -0.173438 0.169738 0.074189 -0.021710 0.194090 0.234900 0.033170 0.084590 -0.130386 0.097589 0.056508 -0.185035 -0.048023 -0.072286 -0.188736 -0.127021 -0.041789 0.051917 -0.142652 0.046137 0.030809 -0.156967 0.146581 -0.123239 0.255234 -0.029442 0.070852 -0.067888 -0.021500 0.047041 -0.123707 0.029834 0.000145 -0.004562 -0.003681 -0.206153 0.106493 -0.110675 0.169503 0.045681 0.004747 0.093024 -0.025528 0.056779 0.059782 -0.120534 -0.032384 -0.085262 0.243780 0.162044 -0.137526 -0.091738 0.050045 0.144495 -0.165136 -0.186924 0.030823 0.053153 0.197681 0.223662 0.022064 0.003202 -0.024336 0.123959 -0.010107 0.084290 0.137769 -0.138592 -0.049584 -0.035911 -0.080225 0.008177 0.107582 -0.050068 0.111890 -0.016628 -0.072132 0.026701 0.034803 -0.039852 0.079409 0.007243 0.187135 0.004809 0.143215 0.112316 0.005733 -0.025242 0.105975 -0.021455 -0.084144 0.071671 0.039247 0.073885 0.045381 -0.013873 0.034038 -0.077718 0.078980 0.166429 0.126670 0.143175 -0.142346 -0.032399 0.071179 -0.068967 0.010746 -0.064242 -0.006592 -0.077852 -0.010893 0.065990 -0.110281 -0.074838 0.034973 0.147838 -0.121335 -0.154952 0.161375 -0.081003 0.033856 0.088001 -0.032041 -0.049034 -0.011083 0.113422 -0.026839 -0.075031 -0.066603 -0.186121 -0.150778 0.045779 0.087078 -0.098411 0.056864 0.177167 -0.122096 -0.073972 0.015486 -0.131340 0.012978 -0.110073 -0.010927 -0.050757 -0.007326 0.012007 0.150999 0.155481 -0.073002 0.050688 0.054087 -0.113686 0.010845 -0.043276 -0.045729 0.183403 0.007836 -0.127994 0.034377 0.111075 0.018356 0.108673 0.102019 0.026513 -0.090341 0.186370 0.069546 -0.036811 -0.015640 0.024841 -0.066877 -0.016313 -0.121145 -0.076258 0.030598 0.028762 0.099692 0.001213 0.005757 -0.194220 0.188298 0.057534 -0.104367 -0.009266 0.060702 0.034658 0.046430 0.133345 -0.015553 -0.048112 0.076634 0.063476 -0.084062 -0.116347 -0.001997 -0.042562 -0.074843 -0.095056 -0.160321 0.065634 -0.254685 0.133669 -0.103004 0.048989 0.004090 0.030592 0.148837 -0.226606 -0.140860 -0.062336 -0.016938 0.018742 -0.134488 -0.037595 -0.256302 -0.264696 -0.113266 0.046848 0.199453 -0.280244 -0.037070 0.080696 -0.082000 -0.096657 -0.063346 -0.164839 -0.083431 -0.110710 0.030953 0.154456 -0.013625 -0.026611 -0.044658 -0.084634 0.060666 -0.099348 0.018465 -0.056645 -0.028819 0.053092 0.038481 0.181900 0.064224 -0.145372 0.115789 -0.087131 0.099206 0.031937 0.073102 -0.028558 0.048451 0.116249 -0.073509 0.067576 0.093822 -0.192306 0.018975 -0.080879 0.042907 -0.066774 0.046183 0.134440 -0.125707\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Construção do modelo Word2Vec-SkipGram a partir do texto ~2 min 33 s\n",
        "from gensim.models import KeyedVectors\n",
        "\n",
        "wv_from_text = KeyedVectors.load_word2vec_format(path_skipgram_300)\n",
        "skipgram_model = wv_from_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "da06b4db-26ef-40c1-85a7-fdfec4ea8f73",
        "id": "OAvKFhqe9K5Q"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "palavras_numeros = tokenizador('texto 55 email@meu.com textosss')\n",
        "vetor_texto = combinacao_de_vetores_soma(palavras_numeros, word2vec_model=skipgram_model)\n",
        "vetor_texto"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "53723e50-ce59-4f67-d536-aeb5f33c7637",
        "id": "PY_gMZRbDV6P"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-6.68270012e-01, -2.79682003e-01,  3.50800250e-03,  2.45561004e-01,\n",
              "       -7.74090067e-02,  7.85348007e-01, -4.56686035e-01,  5.67921989e-01,\n",
              "       -4.25287008e-01, -1.08889401e+00, -9.01659951e-02, -4.68767993e-01,\n",
              "       -4.95117024e-01, -3.37766021e-01,  7.96551973e-01, -2.32274000e-01,\n",
              "        6.96054988e-01, -8.18373997e-01, -6.66531023e-01,  5.30870091e-02,\n",
              "        3.87660000e-01, -1.91991397e+00, -1.18393011e-01,  4.95805996e-01,\n",
              "        1.83799993e-01, -4.68564015e-01,  5.28749879e-02,  5.09001002e-01,\n",
              "       -1.78386799e+00, -1.68957004e-01,  2.13609990e-02,  2.28826996e-01,\n",
              "       -1.56790055e-02,  3.35800001e-01, -7.49274001e-01, -3.33013989e-01,\n",
              "        3.38662986e-01, -4.37913019e-01,  1.16489802e+00, -3.30520123e-02,\n",
              "        1.41941905e+00, -2.18389998e-02,  1.01358299e+00,  1.01134002e-01,\n",
              "        6.17253039e-01, -3.40229003e-01,  9.48933031e-01,  4.34850985e-01,\n",
              "        1.26273605e+00,  1.73449401e+00,  1.76766004e-01, -5.97031016e-01,\n",
              "        1.08357996e-01,  1.01318005e-01,  1.52765999e-01,  7.54983988e-01,\n",
              "        7.17570029e-01,  1.78494999e-01,  1.80030003e-01,  4.98977020e-01,\n",
              "       -2.42632993e-01, -5.56379973e-01,  7.17598006e-01,  7.01451987e-01,\n",
              "        4.85646999e-01,  2.22358996e-01, -3.63718015e-01, -1.49605989e-01,\n",
              "       -9.20834004e-01,  1.59457993e-01,  5.04227009e-01,  3.31487004e-01,\n",
              "       -1.14182602e+00,  1.26414997e-01,  2.55739987e-02, -5.10518000e-01,\n",
              "       -6.85318000e-01,  2.55252993e-01,  2.91882999e-01,  2.98990011e-02,\n",
              "        5.30344010e-01, -8.23562991e-01,  1.03855599e+00,  8.60010996e-01,\n",
              "       -1.79413006e-01,  2.38997992e-01,  9.79262009e-01, -5.49860008e-01,\n",
              "        2.34596994e-01,  8.41157988e-01, -7.32970275e-02, -2.36460082e-02,\n",
              "        6.31248996e-01,  5.01044020e-01, -3.88948999e-01, -3.35143991e-01,\n",
              "        1.28183500e+00,  2.71147987e-01, -7.90232001e-01, -1.55410022e-02,\n",
              "        1.16830599e+00, -3.94799933e-02, -1.31077997e-01, -2.95141995e-01,\n",
              "       -5.12540001e-01,  4.09053992e-01,  4.96472970e-01,  7.62943029e-01,\n",
              "       -3.42180990e-01,  4.26162019e-01,  1.14403599e+00, -1.26439901e+00,\n",
              "       -1.94958005e-01, -7.10915983e-01, -6.26460090e-02,  1.54070804e+00,\n",
              "       -2.73292005e-01, -1.52444705e+00, -7.42264017e-01, -1.34257605e+00,\n",
              "        2.63480004e-01, -5.68059025e-01, -7.68080994e-01, -8.16635996e-01,\n",
              "       -5.07140992e-01,  2.40859997e-01, -8.59119929e-02,  7.83000002e-02,\n",
              "       -1.42526999e-01,  3.41508016e-01, -6.55610006e-01,  1.18706997e-01,\n",
              "        7.79926017e-01, -1.22796997e-01,  4.77930009e-01, -1.45576801e+00,\n",
              "        3.80146988e-01, -5.98180993e-01,  1.88832002e-01, -1.96456008e-01,\n",
              "       -1.08611301e+00,  6.11308027e-01, -3.78964007e-01,  4.71235976e-01,\n",
              "        7.53230982e-01, -3.42996009e-01, -6.85310028e-02,  4.68575992e-01,\n",
              "        3.77498988e-01,  1.18433010e-01,  2.12399848e-03,  7.56261000e-01,\n",
              "        1.00772001e+00,  4.47472004e-01,  2.84949988e-02,  1.20851097e+00,\n",
              "       -3.73613994e-01, -2.69422993e-01, -1.18136699e+00, -1.96996504e+00,\n",
              "       -6.10044988e-01, -1.29227500e+00, -1.80209003e-01, -1.05786802e+00,\n",
              "        4.55270998e-01, -3.34485993e-01, -3.02880004e-01, -3.17702997e-01,\n",
              "       -1.18698996e-01, -2.90198997e-01, -1.37178002e-01,  2.48994004e-01,\n",
              "       -1.19486002e-01, -1.23860016e-02, -3.20323974e-01, -6.69868000e-01,\n",
              "        1.16064598e+00,  1.38247009e-01,  3.54709998e-02,  1.00831300e+00,\n",
              "        1.25200059e-02, -1.00258198e+00,  1.66360298e+00,  8.83644016e-01,\n",
              "        2.09411006e-01, -2.71493982e-01,  1.18433300e+00,  4.68208993e-01,\n",
              "       -2.88863990e-01,  3.63136005e-01,  1.46537989e-01, -6.19873025e-01,\n",
              "       -7.57995993e-04, -7.87747011e-01,  1.05682900e+00,  1.14576196e+00,\n",
              "       -6.02066010e-01,  1.00097898e+00,  5.71731005e-01, -3.64495024e-01,\n",
              "       -2.65487000e-01,  5.89439962e-02, -6.99563012e-01,  7.48376992e-01,\n",
              "        2.53189951e-02,  8.57133007e-01, -8.37679952e-02, -3.04889940e-02,\n",
              "        7.25634977e-01, -4.00998019e-01, -4.45964009e-01,  8.21693028e-01,\n",
              "       -2.78157977e-01, -5.40383026e-01,  1.35944801e+00,  5.47687989e-01,\n",
              "       -5.44366006e-01,  5.48299402e-03, -4.94710001e-01,  5.94453998e-01,\n",
              "        4.85775992e-01, -8.12661007e-01, -4.22020145e-02, -5.35636991e-01,\n",
              "        2.48351987e-01,  1.66762800e+00, -3.50377012e-01,  5.10759950e-02,\n",
              "        9.80955981e-01, -6.31763995e-01,  3.12275010e-01, -3.77842985e-01,\n",
              "        4.07109991e-01,  4.62010987e-01,  4.52184990e-01, -1.07100703e+00,\n",
              "        4.78019975e-02, -3.99556994e-01, -9.22509916e-02,  7.13803001e-01,\n",
              "        1.64293004e-01, -3.05383001e-01,  1.35799004e-01, -1.86129920e-02,\n",
              "        4.21458993e-01, -4.96916988e-01, -7.48270005e-02,  4.89446997e-01,\n",
              "       -4.27821986e-01,  6.85628015e-01,  1.66662998e-01,  9.92019030e-01,\n",
              "       -7.14937001e-01, -4.24147991e-01,  1.31281994e-01,  4.51699980e-02,\n",
              "       -8.65797013e-01,  8.91669989e-02,  3.46373998e-01, -4.09164992e-01,\n",
              "        8.57137974e-01, -2.46144965e-01,  1.43039972e-02, -1.17737602e+00,\n",
              "        1.53569996e+00, -1.52347995e-01, -8.56850017e-02, -6.73180997e-01,\n",
              "        8.87616977e-01, -7.00808004e-01, -4.18718994e-01, -2.24573009e-01,\n",
              "        6.41182005e-01, -3.23020006e-02, -5.49854003e-01,  8.25212970e-01,\n",
              "        4.29492012e-01,  5.47969993e-02,  2.06618011e-01,  2.79179009e-01,\n",
              "       -8.48165989e-01,  6.71620011e-01,  5.42477971e-01,  8.68514981e-01,\n",
              "       -2.26422012e-01,  7.08647996e-01,  1.74152002e-01, -5.38814000e-01,\n",
              "        7.10623033e-01, -9.93166015e-01,  7.86751032e-01, -1.15702996e-01,\n",
              "        3.22924996e-01, -2.69493997e-01, -2.55633004e-01,  5.39976969e-01,\n",
              "       -6.14967994e-01,  4.25468996e-01, -3.10095012e-01,  5.65687995e-01])"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Modelo"
      ],
      "metadata": {
        "id": "6v2xNBnyFukf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Construção da Matriz dos vetores\n",
        "matriz_vetores_sg_treino = matriz_vetores(\n",
        "    artigo_treino['title'], \n",
        "    word2vec_model=skipgram_model)\n",
        "\n",
        "matriz_vetores_sg_teste = matriz_vetores(\n",
        "    artigo_teste['title'], \n",
        "    word2vec_model=skipgram_model)\n",
        "\n",
        "# Previsões\n",
        "LR = LogisticRegression(max_iter=300)\n",
        "LR.fit(X=matriz_vetores_sg_treino, \n",
        "       y=artigo_treino['category'])\n",
        "print(LR.n_iter_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "7ZI1jLRw9eZe",
        "outputId": "17651565-2a03-49ae-f117-ae011c75d1f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[238]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Acurácia do treino\n",
        "acuracia_treino = LR.score(matriz_vetores_sg_treino, artigo_treino['category'])\n",
        "print(f'A acurácia do treino foi de {acuracia_treino:.2f}')\n",
        "\n",
        "# Acurácia do teste\n",
        "acuracia_teste = LR.score(matriz_vetores_sg_teste, artigo_teste['category'])\n",
        "print(f'A acurácia do treino foi de {acuracia_teste:.2f}')\n",
        "\n",
        "CR_skipgram = classification_report(\n",
        "    y_true=artigo_teste['category'], \n",
        "    y_pred=LR.predict(matriz_vetores_sg_teste))\n",
        "print(CR_skipgram)\n",
        "\n",
        "print(CR)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        },
        "outputId": "1670c633-dfc1-427d-9cc9-b17d61cefd30",
        "id": "iTB3bjpLF6Xx"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A acurácia do treino foi de 0.83\n",
            "A acurácia do treino foi de 0.81\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     colunas       0.86      0.72      0.78      6103\n",
            "   cotidiano       0.63      0.81      0.71      1698\n",
            "     esporte       0.93      0.89      0.91      4663\n",
            "   ilustrada       0.15      0.91      0.26       131\n",
            "     mercado       0.85      0.82      0.83      5867\n",
            "       mundo       0.76      0.86      0.81      2051\n",
            "\n",
            "    accuracy                           0.81     20513\n",
            "   macro avg       0.70      0.83      0.72     20513\n",
            "weighted avg       0.84      0.81      0.82     20513\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     colunas       0.86      0.72      0.78      6103\n",
            "   cotidiano       0.61      0.80      0.69      1698\n",
            "     esporte       0.92      0.88      0.90      4663\n",
            "   ilustrada       0.14      0.89      0.24       131\n",
            "     mercado       0.84      0.79      0.82      5867\n",
            "       mundo       0.74      0.86      0.79      2051\n",
            "\n",
            "    accuracy                           0.80     20513\n",
            "   macro avg       0.69      0.82      0.70     20513\n",
            "weighted avg       0.83      0.80      0.81     20513\n",
            "\n"
          ]
        }
      ]
    }
  ]
}