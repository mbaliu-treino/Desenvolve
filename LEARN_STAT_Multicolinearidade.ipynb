{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMf0IW5NM5g5OOV+FHPRI1l",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mbaliu-treino/Desenvolve/blob/main/LEARN_STAT_Multicolinearidade.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font color=orange><b>MULTICOLINERARIDADE</b></font>\n",
        "\n",
        "*Multicollinearity*\n"
      ],
      "metadata": {
        "id": "Ssab6KEgQ-SD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **MATERIAL DE REFERÊNCIA**\n",
        "> \n",
        "> FERRERO, Rosana. [Qué es la multicolinealidad y por que es un problema](https://www.maximaformacion.es/blog-ciencia-datos/que-es-la-multicolinealidad-y-por-que-es-un-problema/)."
      ],
      "metadata": {
        "id": "GIpR5nUHSDsE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color=orange></font>\n",
        "Na maioria das vezes queremos <font color=orange><b>INTERPRETAR</b></font> os modelos para entender as suas previsões. Mas a violação dos <font color=orange><b>PRESSUPOSTOS</b></font> do modelo podem afetar a interpretação. A <font color=orange><b>MULTICOLINEARIDADE</b></font> é um desses casos e pode impedir totalmente a determinação do <font color=orange>efeito das características individuais (variáveis independentes ou preditoras)</font> sobre a <font color=orange>resposta</font> do modelo (variável dependente).\n",
        "Somente com a consideração deste fenômeno é que pode-se fazer uma interpretação dos resultados mais segura.\n",
        "\n",
        "Para isso é importante compreender:\n",
        "- o que são\n",
        "- quais são suas consequencias\n",
        "- como detectá-la\n",
        "- como resolver"
      ],
      "metadata": {
        "id": "wcS0crvSTHtm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color=orange>O que é?</font>"
      ],
      "metadata": {
        "id": "UwzIwZEPXWHI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Multi-col-linear-ity**\n",
        "\n",
        "* multi: múltipla variáveis independentes na regressão múltipla\n",
        "* col: significa junto (together, joint). Refere-se ao movimento linear em pares\n",
        "* linear: ocorrência em uma equação linear\n",
        "* sufixo de qualidade ou estado\n",
        "\n"
      ],
      "metadata": {
        "id": "WMP8d3ETRRWh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A multicolinearidade ocorre quando as variáveis independentes (preditoras) em um modelo de regressão são **correlacionadas** (FERRERO). Com isso, as mudanças em uma variável está associada às mudanças em outra variável.\n",
        "\n",
        "Nesses modelo, essas variáveis possuem o pressuposto de serem independentes. Mas quando o grau de correlação é alto, não se torna possível isolar a relação entre cada variável independente e a variável dependente. Assim, não é possível isolar os efeitos e compreender o comportamento esperado.\n",
        "\n",
        "Desta forma, os coeficientes de regressão do modelo não medirão os efeitos dos preditores na resposta, pois estarão constantes."
      ],
      "metadata": {
        "id": "et0Br1-LR4bp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <font color=orange>Multicolinearidade dos dados</font>\n",
        "\n",
        "- Provém dos próprios dados.\n",
        "    - No caso de querer prever a esperança de vida em países em função do tamanho da população e do PIB. No entanto, estas duas variáveis costumam ser altamente correlacionadas. Isto torna difícil separar os efeitos. Para superar é preciso considerar o fenômeno de multicolinearidade. \n",
        "    - Ocorrem por motivos aleatórios ou erros de medida\n"
      ],
      "metadata": {
        "id": "uXlD9BIuXQF8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <font color=orange>Multicolinearidade Estrutural</font>\n",
        "\n",
        "- Provém dos termos incluídos nos modelos, quando é adicionado um <font color=orange><b>termo de interação</b></font> no modelo, pois ele incluirá o efeito principal dos preditores.\n",
        "- Provém da relação causal entre as variáveis.\n",
        "\n"
      ],
      "metadata": {
        "id": "2qglt6dcYMY_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color=orange>Consequências</font>"
      ],
      "metadata": {
        "id": "K_a_e9zHaI8E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "São observados 3 tipos de consequências causadas pela multicolinearidade.\n",
        "\n",
        "1. <font color=orange>Coeficientes de Correlação Instáveis</font>: Mudança no valor dos coeficientes de regressão do modelo, independentemente se há ou não a adição de novas variáveis independentes, tornando o modelo de difícil interpretação.\n",
        "\n",
        "2. <font color=orange>Precisão</font>: A precisão das estimativas é reduzida, podendo ser calculadas com o erro padrão dos coeficientes de regressão aumentando.\n",
        "\n",
        "3. <font color=orange>Significância estatística</font>: a significância estatística (p-valor) dos coeficientes de regressão do modelo torna-se menos confiável."
      ],
      "metadata": {
        "id": "6ZmMEF5baOqj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Com isso é possível considerar quando é importante corrigir a multicolinearidade. Isso dependerá da gravidade e dos objetivos que desejam ser alcançados.\n",
        "\n",
        "* grau de multicolinearidade, ou seja, em casos moderados talvez não seja necessário corrigir o problema.\n",
        "* ela afeta somente as variáveis independentes específicas que estão correlacionadas. Se elas não forem incluídas no modelo, não será necessário resolvê-las.\n",
        "* afeta apenas o valores-p e os coeficientes: não afeta a previsões, a precisão ou as estatísticas de qualidade de ajuste. Então quando não se pretende entender o papel de cada variável independente e objetiva somente fazer as previsões, não é preciso corrigir."
      ],
      "metadata": {
        "id": "ddMKf_H-bk79"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color=orange>Como detectar?</font>"
      ],
      "metadata": {
        "id": "SU1nBioicvsn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para detectar a multicolinearidade e a sua força pode-se usar:\n",
        "\n",
        "- Matriz de correlação das variáveis independentes\n",
        "    - Para valores acima de 0,8 são considerados casos de significativos de multicolinearidade.\n",
        "\n",
        "- R² (Coeficiente de determinação)\n",
        "    - Quando o R², que indica o ajuste do modelo estatístico aos dados, é muito alto pode indicar há multicolinearidade. [VERIFICAR] \n",
        "\n",
        "- Fator de Inflação de Variância (VIF - Variance Inflation Factor)\n",
        "    - Para alguns casos, a multicolinearidade é mais sutil e pode ser uma combinação não óbvia de duas ou mais variáveis independentes. \n",
        "    - Este fator começa em 1 e crescem, sendo um número grande o maior grau de colinearidade.\n",
        "    - `VIF=1` significa que não há correlação entre esta variável independente e qualquer outra. \n",
        "    - `1< VIF < 5` sugere uma **correlação moderada**, mas não precisaria ser resolvida.\n",
        "    - `VIF > 5` são **níveis críticos** de multicolinearidade.\n",
        "\n",
        "$$VIF = \\frac{1}{(1 - R^2)}$$"
      ],
      "metadata": {
        "id": "gYCl48tDcxl1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Como resolver"
      ],
      "metadata": {
        "id": "URi285Hod76W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nos casos de multicolinearidade moderada, não afetar as variáveis de maior interesse, ou o objetivo ser somente as previsões, a multicolinearidade não precisa ser resolvida."
      ],
      "metadata": {
        "id": "rM4ktwF0d9fj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <font color=orange>Multicolinearidade dos dados</font>\n",
        "\n",
        "Neste caso é preciso considerar os objetivos e o conhecimento prévio na área de estudo para saber qual método é mais indicado para resolver.\n",
        "\n",
        "1. Eliminação de algumas das variáveis ​​independentes altamente correlacionadas.\n",
        "2. Combinação linear das variáveis ​​independentes, por exemplo, por meio de um **PCA** para criar novos preditores independentes e posteriormente o reajuste o modelo de regressão com eles. \n",
        "3. Análise projetada para variáveis ​​altamente correlacionadas, por exemplo, regressão de mínimos quadrados parciais. [Análise fatorial também pode ser uma opção?]\n",
        "4. Regressão que possa lidar com multicolinearidade, por exemplo, regressão LASSO e Ridge. Essas técnicas controlam a multicolinearidade com a regularização.\n",
        "5. Utilizar técnicas de análise de equações estruturais"
      ],
      "metadata": {
        "id": "AQ3fg3DbeRn5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A **análise projetada** é a utilziação de variáveis independentes com baixa correlação entre si. Não é o mesmo que a remoção das variáveis de alta correlação. A análise projetada é geralmente realizada com a ajuda de métodos estatísticos multivariados, como a análise de componentes principais (PCA) ou a análise fatorial (FA). Esses métodos visam encontrar uma combinação linear das variáveis independentes que são menos correlacionadas entre si e, ao mesmo tempo, maximizam a variação dos dados. Essas combinações lineares são chamadas de componentes principais ou fatores, e são utilizadas como variáveis independentes no modelo estatístico.\n",
        "\n",
        "Ou seja, ela consiste em projetar ou transformar as variáveis independentes de tal forma que a multicolinearidade seja reduzida ou eliminada. Isso é feito para melhorar a precisão e a estabilidade dos coeficientes estimados no modelo."
      ],
      "metadata": {
        "id": "t6RmqxbtXfRK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Análise de equações estruturais (Structural Equation Modeling - SEM)**\n",
        "\n",
        "é uma técnica estatística utilizada para modelar relações causais entre várias variáveis. É um método para representar relações estruturais entre as variáveis de forma matemática, como equações, e estimar os parâmetros dessas equações a partir de dados observacionais.\n",
        "\n",
        "A análise de equações estruturais é baseada na ideia de que as variáveis observadas são medidas de variáveis latentes, e que essas variáveis latentes são relacionadas por meio de equações estruturais. Essas equações podem incluir equações de medida, que descrevem como as variáveis observadas são medidas, e equações de estrutura, que descrevem como as variáveis latentes são relacionadas.\n",
        "\n",
        "A análise de equações estruturais permite estimar parâmetros não observáveis, tais como relações de causalidade, e avaliar a qualidade do ajuste do modelo aos dados. Ela também permite testar hipóteses sobre as relações entre as variáveis e realizar a análise de sensibilidade.\n",
        "\n",
        "A análise de equações estruturais é usada para avaliar a validade de teorias, modelos, hipóteses e para fazer inferências causais a partir de dados observacionais. Ela é amplamente utilizada em várias áreas do conhecimento, como psicologia, sociologia, economia, administração e outras ciências sociais e comportamentais.\n",
        "\n",
        "A análise de equações estruturais é composta de duas etapas principais: 1) modelagem estrutural, que envolve a especificação de uma estrutura de equações matemáticas que representam as relações entre as variáveis, e 2) estimação dos parâmetros, que envolve ajustar as equações às observações. Existem vários métodos para estimar os parâmetros, incluindo o método de mínimos quadrados, o método de máxima verossimilhança etc."
      ],
      "metadata": {
        "id": "_yLD_mtIY_R-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "No Python: \n",
        "* statsmodels: A biblioteca statsmodels fornece uma classe StructuralEquationModel que permite estimar modelos de equações estruturais usando o método de máxima verossimilhança.\n",
        "\n",
        "* pysem: A biblioteca pysem fornece uma classe SEM que permite estimar modelos de equações estruturais usando o método de máxima verossimilhança.\n",
        "\n",
        "* semopy: A biblioteca semopy permite estimar modelos de equações estruturais usando o método de máxima verossimilhança ou o método de Bayes.\n",
        "\n",
        "* pylavaan: A biblioteca pylavaan é uma implementação em Python do software Lavaan para análise de equações estruturais. Ela permite estimar modelos de equações estruturais usando o método de máxima verossimilhança.\n",
        "\n",
        "\n",
        "\n",
        "- \"Análise de Equações Estruturais: Teoria, Métodos e Aplicações\" de Rex Kline, é considerado como um dos principais livros sobre análise de equações estruturais, fornece uma introdução abrangente e detalhada à teoria, métodos e aplicações da análise de equações estruturais.\n",
        "\n",
        "- \"Análise de Equações Estruturais: Modelos, Métodos e Aplicações\" de Joe Hair, é um livro introdutório que fornece uma visão geral dos principais conceitos e técnicas da análise de equações estruturais e inclui exemplos práticos de como aplicar esses conceitos e técnicas em diferentes campos de estudo.\n",
        "\n",
        "- \"Análise de Equações Estruturais: Teoria e Prática\" de Tenko Raykov e George A. Marcoulides é um livro que fornece uma introdução abrangente e detalhada aos conceitos e métodos da análise de equações estruturais, incluindo orientações para aplicar esses conceitos e métodos em diferentes campos de estudo."
      ],
      "metadata": {
        "id": "7R-Ssk1PZn2w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <font color=orange>Multicolinearidade Estrutural</font>\n",
        "\n",
        "* **Centralização**: Se tiver apenas multicolinearidade estrutural, pode-se removê-la centralizando os preditores e reajustando-se o modelo. \n",
        "    - Ao centralizar as variáveis ​​independentes, estamos padronizando as variáveis ​​subtraindo a média.\n",
        "\n",
        "    \n",
        "\n"
      ],
      "metadata": {
        "id": "oFkyfP6SeRn7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- a interpretação dos coeficientes de regressão permanece a mesma. Os coeficientes continuam a representar a mudança média na variável dependente dada uma mudança de 1 unidade na variável independente.\n",
        "- Os VIFs do modelo com preditores centrados não apresentarão problemas de multicolinearidade (<5) .\n",
        "- A precisão das estimativas aumenta  (os erros padrão dos coeficientes de regressão diminuem). \n",
        "- Os sinais dos coeficientes de regressão e a significância estatística (p-valor) podem mudar  quando removemos o problema de multicolinearidade. \n",
        "\n",
        "O que NÃO muda quando centralizamos os preditores?\n",
        "\n",
        "- a qualidade do ajuste não muda:  o R-quadrado (R-quadrado ajustado e múltiplo)\n",
        "- as previsões do modelo não são afetadas:  o erro RSE não muda. "
      ],
      "metadata": {
        "id": "37W9g7gBgFZy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bibliografia recomendada"
      ],
      "metadata": {
        "id": "cy0OVdimWrS1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* \"An Introduction to Statistical Learning: with Applications in R\" de Gareth James, Daniela Witten, Trevor Hastie e Robert Tibshirani: Este livro é considerado como um dos melhores recursos para aprender sobre modelagem estatística e apresenta uma introdução aos principais algoritmos de aprendizado de máquina e sua aplicação na análise de dados.\n",
        "\n",
        "* \"Regression Analysis by Example\" de Chatterjee e Hadi: Este livro é uma excelente introdução à análise de regressão e fornece uma ampla variedade de exemplos e exercícios para ilustrar os conceitos.\n",
        "\n",
        "* \"Multivariate Statistical Methods: A Primer\" de Bryan Manly: Este livro fornece uma introdução aos métodos estatísticos multivariados, incluindo análise de componentes principais, análise discriminante, análise de cluster e análise de correspondência, e aborda também a multicolinearidade e outros problemas relacionados.\n",
        "\n",
        "* \"Applied Linear Statistical Models\" de Kutner, Nachtsheim, Neter and Li: Este livro é um recurso completo para análise de regressão linear e fornece uma cobertura abrangente dos métodos estatísticos para anál"
      ],
      "metadata": {
        "id": "7Z-ggcYHWtgh"
      }
    }
  ]
}